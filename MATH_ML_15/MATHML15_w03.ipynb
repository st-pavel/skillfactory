{
  "cells": [
    {
      "cell_type": "markdown",
      "id": "74fa3f4c",
      "metadata": {},
      "source": [
        "# 5. Современные методы: глубокое обучение\n",
        "\n",
        "Глубокое обучение (Deep Learning, DL) — это современное и эффективное решение для многих задач машинного обучения, таких как компьютерное зрение или обработка естественного языка. Deep Learning во многих случаях превосходит классические методы, которые мы рассматривали ранее. Поэтому в последнее время глубокое обучение всё чаще применяется и в рекомендательных системах. Многие крупные компании, такие как AirBnB, Google, Home Depot, LinkedIn и Pinterest, используют рекомендательные системы, построенные именно на основе глубокого обучения.\n",
        "\n",
        "Эмбеддинг — это пространство низкой размерности, которое отражает взаимосвязь векторов из пространства более высокой размерности."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "078db1cb",
      "metadata": {},
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "2025-12-06 09:49:00.742885: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:485] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
            "2025-12-06 09:49:00.760634: E external/local_xla/xla/stream_executor/cuda/cuda_dnn.cc:8454] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
            "2025-12-06 09:49:00.766601: E external/local_xla/xla/stream_executor/cuda/cuda_blas.cc:1452] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "TensorFlow видит GPU: True\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "WARNING: All log messages before absl::InitializeLog() is called are written to STDERR\n",
            "I0000 00:00:1765003744.927797    3040 cuda_executor.cc:1001] could not open file to read NUMA node: /sys/bus/pci/devices/0000:32:00.0/numa_node\n",
            "Your kernel may have been built without NUMA support.\n",
            "I0000 00:00:1765003745.070105    3040 cuda_executor.cc:1001] could not open file to read NUMA node: /sys/bus/pci/devices/0000:32:00.0/numa_node\n",
            "Your kernel may have been built without NUMA support.\n",
            "I0000 00:00:1765003745.070197    3040 cuda_executor.cc:1001] could not open file to read NUMA node: /sys/bus/pci/devices/0000:32:00.0/numa_node\n",
            "Your kernel may have been built without NUMA support.\n"
          ]
        }
      ],
      "source": [
        "# Импорт библиотек\n",
        "from pathlib import Path\n",
        "from warnings import filterwarnings\n",
        "import os\n",
        "import sys\n",
        "os.environ['TF_CPP_MIN_LOG_LEVEL'] = '2' # Скрывает INFO и WARNING, оставляет только ERROR\n",
        "os.environ['TF_ENABLE_ONEDNN_OPTS'] = '0' # Отключить oneDNN сообщения\n",
        "\n",
        "# Автоматическое определение пути к текущему окружению conda\n",
        "conda_prefix = os.environ.get('CONDA_PREFIX')\n",
        "if conda_prefix:\n",
        "    os.environ['XLA_FLAGS'] = f'--xla_gpu_cuda_data_dir={conda_prefix}'\n",
        "\n",
        "# --- 2. Включение ускорения Intel для CPU --- scikit-learn\n",
        "try:\n",
        "    from sklearnex import patch_sklearn, config_context\n",
        "    patch_sklearn()\n",
        "    print('Intel Extension для scikit-learn успешно активирован')\n",
        "except (ImportError, ModuleNotFoundError, Exception) as e:\n",
        "    print(f'Не удалось активировать Intel Extension для scikit-learn: {e}')\n",
        "    print(f'Продолжаем работу без ускорения (это нормально)')\n",
        "\n",
        "\n",
        "from IPython.display import display, Markdown\n",
        "from matplotlib import pyplot as plt\n",
        "from tqdm import tqdm\n",
        "from sklearn.linear_model import LinearRegression\n",
        "from sklearn.metrics import mean_absolute_error, mean_squared_error, mean_absolute_percentage_error\n",
        "from sklearn.model_selection import TimeSeriesSplit\n",
        "from sklearn.feature_extraction.text import TfidfVectorizer\n",
        "from sklearn.metrics.pairwise import linear_kernel\n",
        "\n",
        "#from arch import arch_model\n",
        "from surprise import Dataset\n",
        "from surprise import Reader\n",
        "from surprise.dataset import BUILTIN_DATASETS #с помощью данного объекта мы можем использовать встроенные датасеты\n",
        "from surprise.model_selection import train_test_split\n",
        "from surprise import SVD, KNNBasic, accuracy\n",
        "from surprise import BaselineOnly\n",
        "\n",
        "from scipy.sparse import csr_matrix\n",
        "from scipy.optimize import minimize, least_squares\n",
        "\n",
        "\n",
        "from lightfm import LightFM\n",
        "from lightfm.cross_validation import random_train_test_split\n",
        "from lightfm.evaluation import precision_at_k, recall_at_k\n",
        "\n",
        "import matplotlib.ticker as ticker\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt \n",
        "import seaborn as sns\n",
        "import scipy\n",
        "import sklearn\n",
        "\n",
        "import time\n",
        "\n",
        "from tensorflow.keras.layers import Input, Embedding, Flatten, Dot, Dense, Concatenate\n",
        "from tensorflow.keras.models import Model\n",
        "\n",
        "\n",
        "# Если есть TensorFlow, проверяем его:\n",
        "try:\n",
        "    import tensorflow as tf\n",
        "    print(f\"TensorFlow видит GPU: {len(tf.config.list_physical_devices('GPU')) > 0}\")\n",
        "except ImportError:\n",
        "    pass\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "id": "57e11c9f",
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Текущая рабочая директория: /home/pavel/IDE/skillfactory/MATH_ML_15\n",
            "Рабочая директория уже верная.\n"
          ]
        }
      ],
      "source": [
        "filterwarnings(\"ignore\")\n",
        "# warnings.filterwarnings('ignore', category=UserWarning)\n",
        "# warnings.filterwarnings('ignore', message='.*ConvergenceWarning.*')\n",
        "\n",
        "plt.style.use('seaborn-v0_8') #стиль отрисовки seaborn\n",
        "sns.set_style(\"whitegrid\")\n",
        "%matplotlib inline\n",
        "\n",
        "\n",
        "SEED = 42\n",
        "\n",
        "# Проверка текущей рабочей директории\n",
        "print(f\"Текущая рабочая директория: {os.getcwd()}\")\n",
        "\n",
        "# Текущая рабочая директория (скорее всего .../IDE)\n",
        "current_dir = os.getcwd()\n",
        "\n",
        "# Относительный путь от корня проекта до папки с ноутбуком\n",
        "# Обратите внимание: используем r'' для корректной обработки слешей и пробелов\n",
        "relative_path_to_notebook = r'skillfactory/MATH_ML_15'\n",
        "\n",
        "# Проверяем, не перешли ли мы уже в нужную папку (чтобы не было ошибок при перезапуске ячейки)\n",
        "if not current_dir.endswith(\"MATH_ML_15\"):\n",
        "    # Собираем полный путь\n",
        "    new_dir = os.path.join(current_dir, relative_path_to_notebook)\n",
        "    \n",
        "    # Меняем рабочую директорию\n",
        "    try:\n",
        "        os.chdir(new_dir)\n",
        "        print(f\"Рабочая директория изменена на: {os.getcwd()}\")\n",
        "    except FileNotFoundError:\n",
        "        print(\"Ошибка: путь не найден. Проверьте правильность названий папок.\")\n",
        "else:\n",
        "    print(\"Рабочая директория уже верная.\")"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "6588de55",
      "metadata": {},
      "source": [
        "Давайте разберём несложную задачу, при решении которой мы обучим настоящую нейронную сеть и используем её для создания рекомендаций.\n",
        "\n",
        "Мы будем использовать модуль tensorflow, в котором реализовано много полезных методов для имплементации (внедрения) нейронных сетей. Установим его:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "id": "286f837d",
      "metadata": {},
      "outputs": [],
      "source": [
        "from tensorflow.keras.layers import Input, Embedding, Flatten, Dot, Dense, Concatenate\n",
        "from tensorflow.keras.models import Model"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "0fbad942",
      "metadata": {},
      "source": [
        "Мы будем использовать данные из предыдущего юнита, но лишь те, которые содержат информацию об оценках, выставленных книгам пользователями. Загрузим данные:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "0920c1d7",
      "metadata": {},
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "id": "8a268e16",
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>book_id</th>\n",
              "      <th>user_id</th>\n",
              "      <th>rating</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>1</td>\n",
              "      <td>314</td>\n",
              "      <td>5</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>1</td>\n",
              "      <td>439</td>\n",
              "      <td>3</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>1</td>\n",
              "      <td>588</td>\n",
              "      <td>5</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>1</td>\n",
              "      <td>1169</td>\n",
              "      <td>4</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>1</td>\n",
              "      <td>1185</td>\n",
              "      <td>4</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>981751</th>\n",
              "      <td>10000</td>\n",
              "      <td>48386</td>\n",
              "      <td>5</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>981752</th>\n",
              "      <td>10000</td>\n",
              "      <td>49007</td>\n",
              "      <td>4</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>981753</th>\n",
              "      <td>10000</td>\n",
              "      <td>49383</td>\n",
              "      <td>5</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>981754</th>\n",
              "      <td>10000</td>\n",
              "      <td>50124</td>\n",
              "      <td>5</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>981755</th>\n",
              "      <td>10000</td>\n",
              "      <td>51328</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>981756 rows × 3 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "        book_id  user_id  rating\n",
              "0             1      314       5\n",
              "1             1      439       3\n",
              "2             1      588       5\n",
              "3             1     1169       4\n",
              "4             1     1185       4\n",
              "...         ...      ...     ...\n",
              "981751    10000    48386       5\n",
              "981752    10000    49007       4\n",
              "981753    10000    49383       5\n",
              "981754    10000    50124       5\n",
              "981755    10000    51328       1\n",
              "\n",
              "[981756 rows x 3 columns]"
            ]
          },
          "execution_count": 4,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "df = pd.read_csv('./data/Gooddreadbooks/ratings.csv')\n",
        "df\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "4484ce94",
      "metadata": {},
      "source": [
        "### Задание 5.1\n",
        "\n",
        "1 point possible (graded)\n",
        "\n",
        "Разбейте данные на обучающую и тестовую выборки в отношении 4:1. В качестве значения параметра random_state возьмите число 42.\n",
        "\n",
        "Сколько объектов теперь находится в обучающей выборке?"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "id": "c560307c",
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Количество объектов в обучающей выборке: 785404\n",
            "Количество объектов в тестовой выборке: 196352\n",
            "Общее количество объектов: 981756\n",
            "Проверка: 785404 + 196352 = 981756\n"
          ]
        }
      ],
      "source": [
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "# Разбиваем данные на обучающую и тестовую выборки в отношении 4:1 (80% / 20%)\n",
        "# test_size=0.2 означает, что тестовая выборка составит 20% от всех данных\n",
        "train, test = train_test_split(df, test_size=0.2, random_state=42)\n",
        "\n",
        "# Выводим количество объектов в обучающей выборке\n",
        "print(f\"Количество объектов в обучающей выборке: {len(train)}\")\n",
        "print(f\"Количество объектов в тестовой выборке: {len(test)}\")\n",
        "print(f\"Общее количество объектов: {len(df)}\")\n",
        "print(f\"Проверка: {len(train)} + {len(test)} = {len(train) + len(test)}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "5e8ceb6a",
      "metadata": {},
      "source": [
        "### Задание 5.2\n",
        "\n",
        "1 point possible (graded)\n",
        "\n",
        "Запишите количество уникальных книг в переменную n_books.\n",
        "\n",
        "Сколько в наборе данных уникальных книг?\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "id": "4a81eee4",
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Количество уникальных книг: 10000\n"
          ]
        }
      ],
      "source": [
        "### Задание 5.2 Решение\n",
        "# Подсчитываем количество уникальных книг\n",
        "n_books = df['book_id'].nunique()\n",
        "\n",
        "# Выводим результат\n",
        "print(f\"Количество уникальных книг: {n_books}\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "00cdcee3",
      "metadata": {},
      "source": [
        "### Задание 5.3\n",
        "\n",
        "1 point possible (graded)\n",
        "\n",
        "Запишите количество уникальных пользователей в переменную n_users.\n",
        "\n",
        "Сколько в наборе данных уникальных пользователей?"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "id": "9ed5e60e",
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Количество уникальных пользователей: 53424\n"
          ]
        }
      ],
      "source": [
        "### Задание 5.3 Решение\n",
        "\n",
        "# Подсчитываем количество уникальных пользователей\n",
        "n_users = df['user_id'].nunique()\n",
        "\n",
        "# Выводим результат\n",
        "print(f\"Количество уникальных пользователей: {n_users}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "409e6762",
      "metadata": {},
      "source": [
        "Предварительно вычислим количество уникальных пользователей и книг:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "id": "ea28f358",
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "10000\n",
            "53424\n"
          ]
        }
      ],
      "source": [
        "n_books = df[\"book_id\"].nunique()\n",
        "print(n_books)\n",
        "n_users = df[\"user_id\"].nunique()\n",
        "print(n_users)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "de8bdcde",
      "metadata": {},
      "source": [
        "В первую очередь нам необходимо создать эмбеддинги для книг и пользователей. Создаём эмбеддинги для книг:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "id": "2b229d5a",
      "metadata": {},
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "I0000 00:00:1765003745.434650    3040 cuda_executor.cc:1001] could not open file to read NUMA node: /sys/bus/pci/devices/0000:32:00.0/numa_node\n",
            "Your kernel may have been built without NUMA support.\n",
            "I0000 00:00:1765003745.434789    3040 cuda_executor.cc:1001] could not open file to read NUMA node: /sys/bus/pci/devices/0000:32:00.0/numa_node\n",
            "Your kernel may have been built without NUMA support.\n",
            "I0000 00:00:1765003745.434814    3040 cuda_executor.cc:1001] could not open file to read NUMA node: /sys/bus/pci/devices/0000:32:00.0/numa_node\n",
            "Your kernel may have been built without NUMA support.\n",
            "I0000 00:00:1765003746.167692    3040 cuda_executor.cc:1001] could not open file to read NUMA node: /sys/bus/pci/devices/0000:32:00.0/numa_node\n",
            "Your kernel may have been built without NUMA support.\n",
            "I0000 00:00:1765003746.167798    3040 cuda_executor.cc:1001] could not open file to read NUMA node: /sys/bus/pci/devices/0000:32:00.0/numa_node\n",
            "Your kernel may have been built without NUMA support.\n",
            "I0000 00:00:1765003746.167849    3040 cuda_executor.cc:1001] could not open file to read NUMA node: /sys/bus/pci/devices/0000:32:00.0/numa_node\n",
            "Your kernel may have been built without NUMA support.\n"
          ]
        }
      ],
      "source": [
        "book_input = Input(shape=[1], name=\"Book-Input\")\n",
        "book_embedding = Embedding(n_books+1, 5, name=\"Book-Embedding\")(book_input)\n",
        "book_vec = Flatten(name=\"Flatten-Books\")(book_embedding)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "a74dbc1f",
      "metadata": {},
      "source": [
        "Сначала мы задаём размерность входного слоя (в этом параметре максимальное значение всегда равно длине вектора + 1 ). \n",
        "После этого определяем размер эмбеддинга — в данном случае снижаем размерность до 5. \n",
        "Далее мы разворачиваем результат в массив с одним измерением с помощью слоя Flatten().\n",
        "\n",
        "Делаем то же самое для пользователей:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "id": "80f31c81",
      "metadata": {},
      "outputs": [],
      "source": [
        "user_input = Input(shape=[1], name=\"User-Input\")\n",
        "user_embedding = Embedding(n_users+1, 5, name=\"User-Embedding\")(user_input)\n",
        "user_vec = Flatten(name=\"Flatten-Users\")(user_embedding)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "5d9e6a5c",
      "metadata": {},
      "source": [
        "Теперь, когда мы создали представления как для книг, так и для пользователей, нам необходимо соединить их:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "id": "493de5b5",
      "metadata": {},
      "outputs": [],
      "source": [
        "conc = Concatenate()([book_vec, user_vec])"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "fca5bd7c",
      "metadata": {},
      "source": [
        "Далее начинаем «собирать» нашу нейронную сеть из слоёв. \n",
        "Dense обозначает полносвязный слой. \n",
        "Также мы обозначаем для него количество нейронов (на первом слое будет 128, на втором - 32, на последнем выходном - 1) и данные (на первом слое принимаются данные от соединенных эмбеддингов, на втором - данные с первого слоя, а в последнем слое - данные со второго полносвязного слоя), которые идут на вход."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "id": "a047606f",
      "metadata": {},
      "outputs": [],
      "source": [
        "fc1 = Dense(128, activation='relu')(conc)\n",
        "fc2 = Dense(32, activation='relu')(fc1)\n",
        "out = Dense(1)(fc2)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "e1f96b0a",
      "metadata": {},
      "source": [
        "Собираем модель — передаём входные данные для книг и пользователей, а также архитектуру нейронной сети:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "id": "cc7a3ae0",
      "metadata": {},
      "outputs": [],
      "source": [
        "model2 = Model([user_input, book_input], out)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "43d96b4a",
      "metadata": {},
      "source": [
        "Также нам необходимо задать алгоритм оптимизации и метрику, которую мы будем оптимизировать. В данном случае будем использовать метод adam (это одна из вариаций градиентного спуска) и хорошо известную вам среднеквадратичную ошибку:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "id": "e04b7258",
      "metadata": {},
      "outputs": [],
      "source": [
        "model2.compile(optimizer = 'adam',loss =  'mean_squared_error')"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "7dc6c87a",
      "metadata": {},
      "source": [
        "Теперь будем обучать нашу модель:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "id": "72efdab6",
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 1/5\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "I0000 00:00:1765003748.059449    3142 service.cc:146] XLA service 0x7b7fe4005a60 initialized for platform CUDA (this does not guarantee that XLA will be used). Devices:\n",
            "I0000 00:00:1765003748.059495    3142 service.cc:154]   StreamExecutor device (0): NVIDIA GeForce RTX 4060 Laptop GPU, Compute Capability 8.9\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\u001b[1m   78/24544\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m48s\u001b[0m 2ms/step - loss: 13.8255  "
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "I0000 00:00:1765003749.034715    3142 device_compiler.h:188] Compiled cluster using XLA!  This line is logged at most once for the lifetime of the process.\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\u001b[1m24544/24544\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m61s\u001b[0m 2ms/step - loss: 0.8030\n",
            "Epoch 2/5\n",
            "\u001b[1m24544/24544\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m57s\u001b[0m 2ms/step - loss: 0.6892\n",
            "Epoch 3/5\n",
            "\u001b[1m24544/24544\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m58s\u001b[0m 2ms/step - loss: 0.6652\n",
            "Epoch 4/5\n",
            "\u001b[1m24544/24544\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m59s\u001b[0m 2ms/step - loss: 0.6470\n",
            "Epoch 5/5\n",
            "\u001b[1m24544/24544\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m59s\u001b[0m 2ms/step - loss: 0.6257\n"
          ]
        }
      ],
      "source": [
        "history = model2.fit([train.user_id, train.book_id], train.rating, epochs=5, verbose=1)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "29394f68",
      "metadata": {},
      "source": [
        "В параметр эпох передаём значение 5: у нас будет реализовано пять эпох — пять обучений нейронной сети. На каждой из эпох обновляются веса для минимизации ошибки.\n",
        "\n",
        "Теперь можно оценить качество:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 16,
      "id": "31e5fc28",
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\u001b[1m6136/6136\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 2ms/step - loss: 0.7119\n"
          ]
        },
        {
          "data": {
            "text/plain": [
              "0.7118728160858154"
            ]
          },
          "execution_count": 16,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "model2.evaluate([test.user_id, test.book_id], test.rating)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "87ddae2c",
      "metadata": {},
      "source": [
        "Примечание. К сожалению, результаты этого алгоритма нельзя зафиксировать стандартным ramdom_state, к которому мы привыкли: применяемые методы не используют такой параметр. Поэтому мы опустим здесь сравнение результатов, однако посмотрим, как можно настроить нейронную сеть.\n",
        "\n",
        "Обычно для улучшения качества модели каким-то образом модифицируют нейронную сеть: дополняют её, увеличивают время обучения. Добавим ещё один полносвязный слой с восемью нейронами после полносвязного слоя с 32 нейронами. Обучим нейронную сеть, реализовав десять эпох:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 17,
      "id": "c9a5705f",
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 1/10\n",
            "\u001b[1m24544/24544\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m64s\u001b[0m 3ms/step - loss: 0.6359\n",
            "Epoch 2/10\n",
            "\u001b[1m24544/24544\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m62s\u001b[0m 3ms/step - loss: 0.5870\n",
            "Epoch 3/10\n",
            "\u001b[1m24544/24544\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m64s\u001b[0m 3ms/step - loss: 0.5627\n",
            "Epoch 4/10\n",
            "\u001b[1m24544/24544\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m67s\u001b[0m 3ms/step - loss: 0.5435\n",
            "Epoch 5/10\n",
            "\u001b[1m24544/24544\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m68s\u001b[0m 3ms/step - loss: 0.5277\n",
            "Epoch 6/10\n",
            "\u001b[1m24544/24544\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m68s\u001b[0m 3ms/step - loss: 0.5156\n",
            "Epoch 7/10\n",
            "\u001b[1m24544/24544\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m67s\u001b[0m 3ms/step - loss: 0.5053\n",
            "Epoch 8/10\n",
            "\u001b[1m24544/24544\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m65s\u001b[0m 3ms/step - loss: 0.4964\n",
            "Epoch 9/10\n",
            "\u001b[1m24544/24544\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m69s\u001b[0m 3ms/step - loss: 0.4891\n",
            "Epoch 10/10\n",
            "\u001b[1m24544/24544\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m73s\u001b[0m 3ms/step - loss: 0.4824\n",
            "\u001b[1m6136/6136\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 2ms/step - loss: 0.7756\n"
          ]
        },
        {
          "data": {
            "text/plain": [
              "0.7756327986717224"
            ]
          },
          "execution_count": 17,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "fc1 = Dense(128, activation='relu')(conc)\n",
        "fc2 = Dense(32, activation='relu')(fc1)\n",
        "fc3 = Dense(8, activation='relu')(fc2)\n",
        "out = Dense(1)(fc3)\n",
        "\n",
        "model2 = Model([user_input, book_input], out)\n",
        "model2.compile('adam', 'mean_squared_error')\n",
        "result = model2.fit([train.user_id, train.book_id], train.rating, epochs=10, verbose=1)\n",
        "model2.evaluate([test.user_id, test.book_id], test.rating)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "ef52bd2b",
      "metadata": {},
      "source": [
        "Качество получившейся модели не будет выше качества предыдущей, так как усложнение сети или увеличение количества эпох не всегда даёт высокое качество. Здесь главное, что вы научились корректировать архитектуру нейронной сети.\n",
        "\n",
        "Теперь вы познакомились со всеми методами построения рекомендательных систем — самое время перейти к последнему, практическому юниту."
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "DS_py311_gpu",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.11.14"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}
