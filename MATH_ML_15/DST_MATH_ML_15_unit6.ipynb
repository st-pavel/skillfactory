{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 6. Практика\n",
    "\n",
    "Итак, вы познакомились с основными методами построения рекомендательных систем, и теперь настало время закрепить полученные знания на практике. В предыдущем модуле мы начали строить РС для сервиса чтения статей CI&T DeskDrop. В этом юните мы продолжим работу над ней.\n",
    "\n",
    "Примечание. Если у вас не сохранился код, который мы использовали ранее, вы можете найти его в ноутбуке.\n",
    "Так как теперь вам известны более сложные алгоритмы построения рекомендательных систем, начнём с них.\n",
    "\n",
    "Для начала необходимо построить матрицу, в которой по столбцам будут находиться id статей, по строкам — id пользователей, а на пересечениях строк и столбцов — оценка взаимодействия пользователя со статьёй. Если взаимодействия не было, в соответствующей ячейке должен стоять ноль.\n",
    "\n",
    "Для начала загрузим датасет [\"Articles sharing and reading from CI&T DeskDrop\"](https://www.kaggle.com/datasets/gspmoreira/articles-sharing-reading-from-cit-deskdrop), включающий в себя собранные за один год логи DeskDrop — платформы для внутренних коммуникаций, разработанной CI&T и ориентированной на компании, использующие Google Workspace (Google G Suite). Среди прочего, эта платформа позволяет сотрудникам компаний делиться актуальными статьями со своими коллегами.\n",
    "\n",
    "В датасете содержится около 73 тысяч записей о взаимодействии пользователей с более чем тремя тысячами публичных статей, размещённых на платформе.\n",
    "\n",
    "Информация в наборе данных:\n",
    "\n",
    "Оригинальный URL, название и текст статьи.\n",
    "\n",
    "Контекст посещений пользователей, например дата/время, клиент (мобильное приложение/браузер) и геолокация.\n",
    "\n",
    "Различные типы взаимодействия, что позволяет сделать вывод об уровне заинтересованности пользователя в статьях, например комментарии → лайки → просмотры.\n",
    "\n",
    "Данные включают в себя два файла:\n",
    "\n",
    "shared_articles.csv;\n",
    "users_interactions.csv.\n",
    "Начнём работать с файлом shared_articles.csv. Он содержит информацию о статьях, опубликованных на платформе DeskDrop.\n",
    "\n",
    "Для каждой статьи есть:\n",
    "дата публикации (временная метка),\n",
    "исходный URL-адрес,\n",
    "заголовок,\n",
    "содержание в виде обычного текста,\n",
    "язык статьи (португальский — pt или английский — en),\n",
    "информация о пользователе, который поделился статьёй (автор).\n",
    "Для временной метки существует два возможных типа событий:\n",
    "\n",
    "CONTENT SHARED — статья была опубликована на платформе и доступна для пользователей;\n",
    "CONTENT REMOVED — статья была удалена с платформы и недоступна для дальнейших рекомендаций.\n",
    "Для простоты мы рассматриваем здесь только тип события CONTENT SHARED."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "_cell_guid": "719f3966-e6fd-49c8-9f60-7bd741542450",
    "_uuid": "b61cd3125a7f8f991fc1bda85ae3cd26f74090ae",
    "id": "wNfQwXV17w32"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Intel Extension для scikit-learn успешно активирован\n",
      "TensorFlow видит GPU: True\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Extension for Scikit-learn* enabled (https://github.com/uxlfoundation/scikit-learn-intelex)\n"
     ]
    }
   ],
   "source": [
    "# Импорт библиотек\n",
    "from pathlib import Path\n",
    "from warnings import filterwarnings\n",
    "import os\n",
    "import sys\n",
    "os.environ['TF_CPP_MIN_LOG_LEVEL'] = '2' # Скрывает INFO и WARNING, оставляет только ERROR\n",
    "os.environ['TF_ENABLE_ONEDNN_OPTS'] = '0' # Отключить oneDNN сообщения\n",
    "\n",
    "# Автоматическое определение пути к текущему окружению conda\n",
    "conda_prefix = os.environ.get('CONDA_PREFIX')\n",
    "if conda_prefix:\n",
    "    os.environ['XLA_FLAGS'] = f'--xla_gpu_cuda_data_dir={conda_prefix}'\n",
    "\n",
    "# --- 2. Включение ускорения Intel для CPU --- scikit-learn\n",
    "try:\n",
    "    from sklearnex import patch_sklearn, config_context\n",
    "    patch_sklearn()\n",
    "    print('Intel Extension для scikit-learn успешно активирован')\n",
    "except (ImportError, ModuleNotFoundError, Exception) as e:\n",
    "    print(f'Не удалось активировать Intel Extension для scikit-learn: {e}')\n",
    "    print(f'Продолжаем работу без ускорения (это нормально)')\n",
    "\n",
    "\n",
    "from IPython.display import display, Markdown\n",
    "from matplotlib import pyplot as plt\n",
    "from tqdm import tqdm\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.metrics import mean_absolute_error, mean_squared_error, mean_absolute_percentage_error\n",
    "from sklearn.model_selection import TimeSeriesSplit\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.metrics.pairwise import linear_kernel\n",
    "\n",
    "#from arch import arch_model\n",
    "from surprise import Dataset\n",
    "from surprise import Reader\n",
    "from surprise.dataset import BUILTIN_DATASETS #с помощью данного объекта мы можем использовать встроенные датасеты\n",
    "from surprise.model_selection import train_test_split\n",
    "from surprise import SVD, KNNBasic, accuracy\n",
    "from surprise import BaselineOnly\n",
    "\n",
    "from scipy.sparse import csr_matrix\n",
    "from scipy.sparse.linalg import svds\n",
    "from scipy.linalg import svd\n",
    "from scipy.optimize import minimize, least_squares\n",
    "\n",
    "\n",
    "from lightfm import LightFM\n",
    "from lightfm.cross_validation import random_train_test_split\n",
    "from lightfm.evaluation import precision_at_k, recall_at_k\n",
    "\n",
    "import matplotlib.ticker as ticker\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt \n",
    "import seaborn as sns\n",
    "import scipy\n",
    "import sklearn\n",
    "import math\n",
    "\n",
    "import time\n",
    "\n",
    "from tensorflow.keras.layers import Input, Embedding, Flatten, Dot, Dense, Concatenate\n",
    "from tensorflow.keras.models import Model\n",
    "\n",
    "\n",
    "# Если есть TensorFlow, проверяем его:\n",
    "try:\n",
    "    import tensorflow as tf\n",
    "    print(f\"TensorFlow видит GPU: {len(tf.config.list_physical_devices('GPU')) > 0}\")\n",
    "except ImportError:\n",
    "    pass\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Текущая рабочая директория: /home/pavel/IDE/skillfactory/MATH_ML_15\n",
      "Рабочая директория уже верная.\n"
     ]
    }
   ],
   "source": [
    "filterwarnings(\"ignore\")\n",
    "# warnings.filterwarnings('ignore', category=UserWarning)\n",
    "# warnings.filterwarnings('ignore', message='.*ConvergenceWarning.*')\n",
    "\n",
    "plt.style.use('seaborn-v0_8') #стиль отрисовки seaborn\n",
    "sns.set_style(\"whitegrid\")\n",
    "%matplotlib inline\n",
    "\n",
    "\n",
    "SEED = 42\n",
    "\n",
    "# Проверка текущей рабочей директории\n",
    "print(f\"Текущая рабочая директория: {os.getcwd()}\")\n",
    "\n",
    "# Текущая рабочая директория (скорее всего .../IDE)\n",
    "current_dir = os.getcwd()\n",
    "\n",
    "# Относительный путь от корня проекта до папки с ноутбуком\n",
    "# Обратите внимание: используем r'' для корректной обработки слешей и пробелов\n",
    "relative_path_to_notebook = r'skillfactory/MATH_ML_15'\n",
    "\n",
    "# Проверяем, не перешли ли мы уже в нужную папку (чтобы не было ошибок при перезапуске ячейки)\n",
    "if not current_dir.endswith(\"MATH_ML_15\"):\n",
    "    # Собираем полный путь\n",
    "    new_dir = os.path.join(current_dir, relative_path_to_notebook)\n",
    "    \n",
    "    # Меняем рабочую директорию\n",
    "    try:\n",
    "        os.chdir(new_dir)\n",
    "        print(f\"Рабочая директория изменена на: {os.getcwd()}\")\n",
    "    except FileNotFoundError:\n",
    "        print(\"Ошибка: путь не найден. Проверьте правильность названий папок.\")\n",
    "else:\n",
    "    print(\"Рабочая директория уже верная.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "_cell_guid": "e601f966-d03f-4edc-886f-ca3d511a8045",
    "_uuid": "569c301bd128f66f29b4d97c34171e4d1712015a",
    "id": "y7UAvo9Y7w33"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>timestamp</th>\n",
       "      <th>eventType</th>\n",
       "      <th>contentId</th>\n",
       "      <th>authorPersonId</th>\n",
       "      <th>authorSessionId</th>\n",
       "      <th>authorUserAgent</th>\n",
       "      <th>authorRegion</th>\n",
       "      <th>authorCountry</th>\n",
       "      <th>contentType</th>\n",
       "      <th>url</th>\n",
       "      <th>title</th>\n",
       "      <th>text</th>\n",
       "      <th>lang</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1459193988</td>\n",
       "      <td>CONTENT SHARED</td>\n",
       "      <td>-4110354420726924665</td>\n",
       "      <td>4340306774493623681</td>\n",
       "      <td>8940341205206233829</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>HTML</td>\n",
       "      <td>http://www.nytimes.com/2016/03/28/business/dea...</td>\n",
       "      <td>Ethereum, a Virtual Currency, Enables Transact...</td>\n",
       "      <td>All of this work is still very early. The firs...</td>\n",
       "      <td>en</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1459194146</td>\n",
       "      <td>CONTENT SHARED</td>\n",
       "      <td>-7292285110016212249</td>\n",
       "      <td>4340306774493623681</td>\n",
       "      <td>8940341205206233829</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>HTML</td>\n",
       "      <td>http://cointelegraph.com/news/bitcoin-future-w...</td>\n",
       "      <td>Bitcoin Future: When GBPcoin of Branson Wins O...</td>\n",
       "      <td>The alarm clock wakes me at 8:00 with stream o...</td>\n",
       "      <td>en</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1459194474</td>\n",
       "      <td>CONTENT SHARED</td>\n",
       "      <td>-6151852268067518688</td>\n",
       "      <td>3891637997717104548</td>\n",
       "      <td>-1457532940883382585</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>HTML</td>\n",
       "      <td>https://cloudplatform.googleblog.com/2016/03/G...</td>\n",
       "      <td>Google Data Center 360° Tour</td>\n",
       "      <td>We're excited to share the Google Data Center ...</td>\n",
       "      <td>en</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1459194497</td>\n",
       "      <td>CONTENT SHARED</td>\n",
       "      <td>2448026894306402386</td>\n",
       "      <td>4340306774493623681</td>\n",
       "      <td>8940341205206233829</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>HTML</td>\n",
       "      <td>https://bitcoinmagazine.com/articles/ibm-wants...</td>\n",
       "      <td>IBM Wants to \"Evolve the Internet\" With Blockc...</td>\n",
       "      <td>The Aite Group projects the blockchain market ...</td>\n",
       "      <td>en</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>1459194522</td>\n",
       "      <td>CONTENT SHARED</td>\n",
       "      <td>-2826566343807132236</td>\n",
       "      <td>4340306774493623681</td>\n",
       "      <td>8940341205206233829</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>HTML</td>\n",
       "      <td>http://www.coindesk.com/ieee-blockchain-oxford...</td>\n",
       "      <td>IEEE to Talk Blockchain at Cloud Computing Oxf...</td>\n",
       "      <td>One of the largest and oldest organizations fo...</td>\n",
       "      <td>en</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    timestamp       eventType            contentId       authorPersonId  \\\n",
       "1  1459193988  CONTENT SHARED -4110354420726924665  4340306774493623681   \n",
       "2  1459194146  CONTENT SHARED -7292285110016212249  4340306774493623681   \n",
       "3  1459194474  CONTENT SHARED -6151852268067518688  3891637997717104548   \n",
       "4  1459194497  CONTENT SHARED  2448026894306402386  4340306774493623681   \n",
       "5  1459194522  CONTENT SHARED -2826566343807132236  4340306774493623681   \n",
       "\n",
       "       authorSessionId authorUserAgent authorRegion authorCountry contentType  \\\n",
       "1  8940341205206233829             NaN          NaN           NaN        HTML   \n",
       "2  8940341205206233829             NaN          NaN           NaN        HTML   \n",
       "3 -1457532940883382585             NaN          NaN           NaN        HTML   \n",
       "4  8940341205206233829             NaN          NaN           NaN        HTML   \n",
       "5  8940341205206233829             NaN          NaN           NaN        HTML   \n",
       "\n",
       "                                                 url  \\\n",
       "1  http://www.nytimes.com/2016/03/28/business/dea...   \n",
       "2  http://cointelegraph.com/news/bitcoin-future-w...   \n",
       "3  https://cloudplatform.googleblog.com/2016/03/G...   \n",
       "4  https://bitcoinmagazine.com/articles/ibm-wants...   \n",
       "5  http://www.coindesk.com/ieee-blockchain-oxford...   \n",
       "\n",
       "                                               title  \\\n",
       "1  Ethereum, a Virtual Currency, Enables Transact...   \n",
       "2  Bitcoin Future: When GBPcoin of Branson Wins O...   \n",
       "3                       Google Data Center 360° Tour   \n",
       "4  IBM Wants to \"Evolve the Internet\" With Blockc...   \n",
       "5  IEEE to Talk Blockchain at Cloud Computing Oxf...   \n",
       "\n",
       "                                                text lang  \n",
       "1  All of this work is still very early. The firs...   en  \n",
       "2  The alarm clock wakes me at 8:00 with stream o...   en  \n",
       "3  We're excited to share the Google Data Center ...   en  \n",
       "4  The Aite Group projects the blockchain market ...   en  \n",
       "5  One of the largest and oldest organizations fo...   en  "
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "articles_df = pd.read_csv('./data/shared_articles.csv')\n",
    "articles_df = articles_df[articles_df['eventType'] == 'CONTENT SHARED']\n",
    "articles_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "_cell_guid": "445d39ec-f6b0-4155-9f92-0a2540918bd1",
    "_uuid": "9829842326037e364de457f832deceae074d6164",
    "id": "ivJz48uV7w33"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>timestamp</th>\n",
       "      <th>eventType</th>\n",
       "      <th>contentId</th>\n",
       "      <th>personId</th>\n",
       "      <th>sessionId</th>\n",
       "      <th>userAgent</th>\n",
       "      <th>userRegion</th>\n",
       "      <th>userCountry</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1465413032</td>\n",
       "      <td>VIEW</td>\n",
       "      <td>-3499919498720038879</td>\n",
       "      <td>-8845298781299428018</td>\n",
       "      <td>1264196770339959068</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1465412560</td>\n",
       "      <td>VIEW</td>\n",
       "      <td>8890720798209849691</td>\n",
       "      <td>-1032019229384696495</td>\n",
       "      <td>3621737643587579081</td>\n",
       "      <td>Mozilla/5.0 (Macintosh; Intel Mac OS X 10_11_2...</td>\n",
       "      <td>NY</td>\n",
       "      <td>US</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1465416190</td>\n",
       "      <td>VIEW</td>\n",
       "      <td>310515487419366995</td>\n",
       "      <td>-1130272294246983140</td>\n",
       "      <td>2631864456530402479</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1465413895</td>\n",
       "      <td>FOLLOW</td>\n",
       "      <td>310515487419366995</td>\n",
       "      <td>344280948527967603</td>\n",
       "      <td>-3167637573980064150</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1465412290</td>\n",
       "      <td>VIEW</td>\n",
       "      <td>-7820640624231356730</td>\n",
       "      <td>-445337111692715325</td>\n",
       "      <td>5611481178424124714</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    timestamp eventType            contentId             personId  \\\n",
       "0  1465413032      VIEW -3499919498720038879 -8845298781299428018   \n",
       "1  1465412560      VIEW  8890720798209849691 -1032019229384696495   \n",
       "2  1465416190      VIEW   310515487419366995 -1130272294246983140   \n",
       "3  1465413895    FOLLOW   310515487419366995   344280948527967603   \n",
       "4  1465412290      VIEW -7820640624231356730  -445337111692715325   \n",
       "\n",
       "             sessionId                                          userAgent  \\\n",
       "0  1264196770339959068                                                NaN   \n",
       "1  3621737643587579081  Mozilla/5.0 (Macintosh; Intel Mac OS X 10_11_2...   \n",
       "2  2631864456530402479                                                NaN   \n",
       "3 -3167637573980064150                                                NaN   \n",
       "4  5611481178424124714                                                NaN   \n",
       "\n",
       "  userRegion userCountry  \n",
       "0        NaN         NaN  \n",
       "1         NY          US  \n",
       "2        NaN         NaN  \n",
       "3        NaN         NaN  \n",
       "4        NaN         NaN  "
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "interactions_df = pd.read_csv('./data/users_interactions.csv')\n",
    "interactions_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Теперь откроем второй файл — users_interactions.csv .\n",
    "\n",
    "Давайте предварительно преобразуем столбцы personId, contentId в таблицах к строкам. Это преобразование пригодится нам в дальнейшем:\n",
    "\n",
    "```\n",
    "interactions_df.personId = interactions_df.personId.astype(str)\n",
    "interactions_df.contentId = interactions_df.contentId.astype(str)\n",
    "articles_df.contentId = articles_df.contentId.astype(str)\n",
    "```\n",
    "\n",
    "В колонке eventType описаны действия, которые могли совершать пользователи при взаимодействии со статьёй:\n",
    "\n",
    "VIEW — просмотр,\n",
    "LIKE — лайк,\n",
    "COMMENT CREATED — комментарий,\n",
    "FOLLOW — подписка,\n",
    "BOOKMARK — добавление в закладки.\n",
    "\n",
    "В первую очередь нам необходимо понять, как определить, что какая-то статья популярнее других. Если бы из возможных реакций у нас были только лайки или только просмотры, то статьи было бы легко ранжировать в соответствии с этими значениями. Однако у нас есть информация о различных действиях пользователя, и на её основе мы должны создать некий универсальный индекс популярности. Составим его из реакций пользователей, придав им разные веса:\n",
    "```\n",
    "event_type = {\n",
    "   'VIEW': 1.0,\n",
    "   'LIKE': 2.0, \n",
    "   'BOOKMARK': 2.5, \n",
    "   'FOLLOW': 3.0,\n",
    "   'COMMENT CREATED': 4.0,  \n",
    "}\n",
    "```\n",
    "Веса здесь подобраны исходя из важности каждого действия: оставить комментарий — значит, показать наибольшую вовлечённость, а обычный просмотр, напротив, демонстрирует наименьшую вовлечённость."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "id": "IeZKXvNf7w34"
   },
   "outputs": [],
   "source": [
    "interactions_df.personId = interactions_df.personId.astype(str)\n",
    "interactions_df.contentId = interactions_df.contentId.astype(str)\n",
    "articles_df.contentId = articles_df.contentId.astype(str)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "_cell_guid": "3239c376-05b8-4a58-9afc-f6f57f67405f",
    "_uuid": "b06f8c0b082f0ad07bf773a5ad2fae33c1f7acc2",
    "id": "7WY1Hykv7w34"
   },
   "outputs": [],
   "source": [
    "event_type_strength = {\n",
    "   'VIEW': 1.0,\n",
    "   'LIKE': 2.0, \n",
    "   'BOOKMARK': 2.5, \n",
    "   'FOLLOW': 3.0,\n",
    "   'COMMENT CREATED': 4.0,  \n",
    "}\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Создаем признак, который будет отражать числовой вес для взаимодействия со статьёй (в соответствии с приведёнными выше весами). Вычислим среднее значение для полученного признака."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "id": "Z69ayTpr7w34"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Среднее значение eventStrength: 1.24\n"
     ]
    }
   ],
   "source": [
    "interactions_df['eventStrength'] = interactions_df.eventType.apply(lambda x: event_type_strength[x])\n",
    "\n",
    "mean_strength = interactions_df['eventStrength'].mean()\n",
    "print(f\"Среднее значение eventStrength: {mean_strength:.2f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Оставим только тех пользователей, которые взаимодействовали хотя бы с пятью статьями."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "_cell_guid": "bad1d8ea-9b67-4a47-80c5-87a5e55c4f38",
    "_uuid": "1698c88340183baa7f3ebb8c3b60eaa8e6ca708f",
    "id": "Rr43SIq_7w35"
   },
   "outputs": [],
   "source": [
    "users_interactions_count_df = (\n",
    "    interactions_df\n",
    "    .groupby(['personId', 'contentId'])\n",
    "    .first()\n",
    "    .reset_index()\n",
    "    .groupby('personId').size())\n",
    "\n",
    "users_with_enough_interactions_df = \\\n",
    "    users_interactions_count_df[users_interactions_count_df >= 5].reset_index()[['personId']]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Теперь оставим только те взаимодействия, которые касаются только отфильтрованных пользователей (то есть тех, которые взаимодействовали как минимум с пятью статьями). Сколько всего таких взаимодействий?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "_cell_guid": "4e79a418-a9d6-4e01-9f38-9b290a645626",
    "_uuid": "0f428a4c6e76f95de7ea328dc33c6539389ae5f0",
    "id": "g5ni03Z57w35"
   },
   "outputs": [],
   "source": [
    "interactions_from_selected_users_df = interactions_df.loc[np.in1d(interactions_df.personId,\n",
    "            users_with_enough_interactions_df)]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Сейчас каждое отдельное взаимодействие пользователя со статьёй выделено в отдельную запись, то есть пользователь мог просмотреть статью, лайкнуть и прокомментировать её, и всё это отразилось в трёх действиях. Для удобства соединим все эти действия в некоторый коэффициент, который будет отражать интерес пользователя к статье. Так как каждому возможному действию мы ранее уже присвоили вес, то, по сути, нам нужно просто сложить все действия. Однако полученное число будет увеличиваться с количеством действий, и будет очень большой разброс возможных значений. В таких случаях обычно логарифмируют полученный результат с помощью следующей функции:\n",
    "``` python \n",
    "def smooth_user_preference(x):\n",
    "    return math.log(1+x, 2)\n",
    "\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "_cell_guid": "54c82dd1-1102-4f11-ac6a-7993f8e5e842",
    "_uuid": "dcd64b20b47cf2c365341303ff410626a801f7a6",
    "id": "5mXOPSjW7w36"
   },
   "outputs": [],
   "source": [
    "def smooth_user_preference(x):\n",
    "    return math.log(1+x, 2)\n",
    "    \n",
    "interactions_full_df = (\n",
    "    interactions_from_selected_users_df\n",
    "    .groupby(['personId', 'contentId']).eventStrength.sum()\n",
    "    .apply(smooth_user_preference)\n",
    "    .reset_index().set_index(['personId', 'contentId'])\n",
    ")\n",
    "interactions_full_df['last_timestamp'] = (\n",
    "    interactions_from_selected_users_df\n",
    "    .groupby(['personId', 'contentId'])['timestamp'].max()\n",
    ")\n",
    "        \n",
    "interactions_full_df = interactions_full_df.reset_index()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Разделим данные на обучающую и тестовую выборки, выбрав в качестве временной отсечки значение 1475519545"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "_cell_guid": "e594a5ef-255a-4d30-9ab2-7cebe12fe798",
    "_uuid": "babda61be5306281b34422dbded67675a0aab17d",
    "id": "Qix5uD7f7w37"
   },
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "split_ts = 1475519545\n",
    "interactions_train_df = interactions_full_df.loc[interactions_full_df.last_timestamp < split_ts].copy()\n",
    "interactions_test_df = interactions_full_df.loc[interactions_full_df.last_timestamp >= split_ts].copy()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Задание 6.1\n",
    "\n",
    "1 point possible (graded)\n",
    "\n",
    "Найдите оценку взаимодействия пользователя с ID -1032019229384696495 со статьёй с ID 943818026930898372. Результат округлите до двух знаков после точки-разделителя.\n",
    "\n",
    "Примечание. Здесь и далее (пока не будет указано иное) необходимо работать с обучающей выборкой."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "id": "6JS-ZrRl7w38"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Score: 2.321928094887362\n",
      "Rounded Score: 2.32\n"
     ]
    }
   ],
   "source": [
    "# Target User and Item\n",
    "target_user = '-1032019229384696495'\n",
    "target_item = '943818026930898372'\n",
    "\n",
    "# Find the value\n",
    "result_row = interactions_train_df[\n",
    "    (interactions_train_df['personId'] == target_user) & \n",
    "    (interactions_train_df['contentId'] == target_item)\n",
    "]\n",
    "\n",
    "if not result_row.empty:\n",
    "    score = result_row['eventStrength'].values[0]\n",
    "    print(f\"Score: {score}\")\n",
    "    print(f\"Rounded Score: {score:.2f}\")\n",
    "else:\n",
    "    print(\"Interaction not found in training set.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Теперь давайте попробуем применить memory-based-подход коллаборативной фильтрации.\n",
    "\n",
    "Примечание. Данных достаточно много, поэтому для увеличения скорости работы преобразуйте таблицу в массив numpy."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Задание 6.2\n",
    "\n",
    "1 point possible (graded)\n",
    "\n",
    "Найдите среднее арифметическое всех чисел в получившемся массиве. Результат округлите до трёх знаков после точки-разделителя.\n",
    "\n",
    "Теперь давайте попробуем применить memory-based-подход коллаборативной фильтрации.\n",
    "\n",
    "Примечание. Данных достаточно много, поэтому для увеличения скорости работы преобразуйте таблицу в массив numpy.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Global Mean: 0.016668620737604056\n",
      "Rounded Global Mean: 0.017\n"
     ]
    }
   ],
   "source": [
    "### Решение - Задание 6.2\n",
    "\n",
    "# Создаем матрицу взаимодействий\n",
    "users_items_pivot_matrix_df = interactions_train_df.pivot(index='personId', \n",
    "                                                          columns='contentId', \n",
    "                                                          values='eventStrength').fillna(0)\n",
    "\n",
    "# Преобразуем в массив numpy\n",
    "ratings_matrix = users_items_pivot_matrix_df.values\n",
    "\n",
    "# Находим среднее арифметическое\n",
    "global_mean = np.mean(ratings_matrix)\n",
    "print(f\"Global Mean: {global_mean}\")\n",
    "print(f\"Rounded Global Mean: {global_mean:.3f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Перейдём к реализации коллаборативной фильтрации. Ранее мы делали это с помощью библиотеки surprise, однако это не всегда удобно, так как эта библиотека имеет ограниченное количество метрик для оценки качества и небольшой потенциал для более тонкой настройки алгоритма. Поэтому давайте попробуем реализовать алгоритмы коллаборативной фильтрации «с нуля». Такая практика применяется, если необходимо выстроить более сложную систему, чем могут предложить готовые модули. Кроме того, «ручная» реализация алгоритмов позволит лучше понять принцип их работы."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Задание 6.3\n",
    "\n",
    "1 point possible (graded)\n",
    "\n",
    "Постройте матрицу схожести. Для этого вычислите все попарные коэффициенты корреляции для матрицы, полученной в предыдущем задании. Для каждой пары учитывайте только ненулевые значения (так как нулевые обозначают отсутствие взаимодействия и не интересуют нас). Выведите результат, полученный в ячейке с третьим индексом по строкам и сороковым — по столбцам. Ответ округлите до двух знаков после точки-разделителя.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Correlation calculation took: 0 days 00:00:00.971377\n",
      "Similarity Matrix Shape: (1112, 1112)\n",
      "Similarity at [3, 40]: -0.33333333333333326\n",
      "Rounded Similarity at [3, 40]: -0.33\n"
     ]
    }
   ],
   "source": [
    "### Решение - Задание 6.3\n",
    "# For 6.3 we need to consider only non-zero values for correlation.\n",
    "# We can use pandas corr() which ignores NaNs. \n",
    "# So we replace 0 with NaN.\n",
    "users_items_pivot_nan = users_items_pivot_matrix_df.replace(0, np.nan)\n",
    "\n",
    "# Calculate User-User similarity (Correlation between rows)\n",
    "# Pandas corr() computes pairwise correlation of columns.\n",
    "# To get row correlation (Users), we transpose first.\n",
    "# Transposed: Columns become Users.\n",
    "start_time = pd.Timestamp.now()\n",
    "similarity_matrix = users_items_pivot_nan.T.corr(method='pearson')\n",
    "end_time = pd.Timestamp.now()\n",
    "print(f\"Correlation calculation took: {end_time - start_time}\")\n",
    "\n",
    "# Shape check\n",
    "print(f\"Similarity Matrix Shape: {similarity_matrix.shape}\")\n",
    "\n",
    "# Get value at index [3, 40]\n",
    "# Use iloc for integer-location based indexing\n",
    "value_3_40 = similarity_matrix.iloc[3, 40]\n",
    "print(f\"Similarity at [3, 40]: {value_3_40}\")\n",
    "print(f\"Rounded Similarity at [3, 40]: {value_3_40:.2f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Теперь у нас есть матрицы схожести пользователей. Их можно использовать для построения рекомендаций. Чтобы это сделать, надо реализовать следующий алгоритм.\n",
    "\n",
    "Для каждого пользователя:\n",
    "\n",
    "- Найти пользователей с похожестью больше 0.\n",
    "- Для каждой статьи вычислить долю пользователей (среди выделенных на первом шаге), которые взаимодействовали со статьёй.\n",
    "- Порекомендовать статьи (не более 10) с наибольшими долями со второго шага (среди тех, которые пользователь ещё не видел)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Задание 6.4\n",
    "\n",
    "1 point possible (graded)\n",
    "\n",
    "Постройте рекомендательную систему по алгоритму, описанному выше. Найдите первую рекомендацию для строки 35 (если считать с нуля)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Target User ID (Index 35): -174458633445209100\n",
      "Count of users with similarity > 0: 49\n",
      "Top Recommendations:\n",
      "contentId\n",
      "-5148591903395022444    0.469388\n",
      "-2447632164766022033    0.387755\n",
      "4259370161044254504     0.387755\n",
      "1356221992133852808     0.346939\n",
      "-8208801367848627943    0.346939\n",
      "2581138407738454418     0.326531\n",
      "6437568358552101410     0.306122\n",
      "-820343972901090172     0.306122\n",
      "-6783772548752091658    0.306122\n",
      "-133139342397538859     0.306122\n",
      "dtype: float64\n",
      "Answer (First Recommendation ContentID): -5148591903395022444\n"
     ]
    }
   ],
   "source": [
    "### Решение - Задание 6.4\n",
    "# Get the user ID at index 35 (iloc is purely integer-location based)\n",
    "# Check if index is valid\n",
    "if len(users_items_pivot_matrix_df) > 35:\n",
    "    target_user_id = users_items_pivot_matrix_df.index[35]\n",
    "    print(f\"Target User ID (Index 35): {target_user_id}\")\n",
    "\n",
    "    # Get similarity row for this user\n",
    "    user_similarities = similarity_matrix.loc[target_user_id]\n",
    "\n",
    "    # Step 1: Find users with similarity > 0\n",
    "    similar_users_ids = user_similarities[user_similarities > 0].index\n",
    "    print(f\"Count of users with similarity > 0: {len(similar_users_ids)}\")\n",
    "\n",
    "    # Step 2: Calculate interaction share for each article\n",
    "    # Subset interactions to similar users\n",
    "    similar_users_interactions = users_items_pivot_matrix_df.loc[similar_users_ids]\n",
    "\n",
    "    # Count users who interacted (value > 0)\n",
    "    article_interaction_counts = (similar_users_interactions > 0).sum()\n",
    "\n",
    "    # Calculate share\n",
    "    article_shares = article_interaction_counts / len(similar_users_ids)\n",
    "\n",
    "    # Step 3: Filter out articles the target user has already seen\n",
    "    target_user_seen_mask = users_items_pivot_matrix_df.loc[target_user_id] > 0\n",
    "    seen_articles = target_user_seen_mask[target_user_seen_mask].index\n",
    "    \n",
    "    # Drop seen articles\n",
    "    recommendations = article_shares.drop(index=seen_articles, errors='ignore')\n",
    "\n",
    "    # Sort descending\n",
    "    top_recommendations = recommendations.sort_values(ascending=False).head(10)\n",
    "\n",
    "    print(\"Top Recommendations:\")\n",
    "    print(top_recommendations)\n",
    "\n",
    "    if not top_recommendations.empty:\n",
    "        print(f\"Answer (First Recommendation ContentID): {top_recommendations.index[0]}\")\n",
    "else:\n",
    "    print(\"Error: DataFrame has fewer than 36 rows.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "После того как сделаны предсказания, можно вычислить качество по метрике, которую мы определили в предыдущем модуле при решении этой задачи:\n",
    "``` python\n",
    "def calc_precision(column):\n",
    "    return ( interactions.apply(  lambda row:len(set(row['true_test']).intersection(\n",
    "                set(row[column]))) /min(len(row['true_test']) + 0.001, 10.0), axis=1)).mean()\n",
    "```\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Задание 6.5\n",
    "\n",
    "1 point possible (graded)\n",
    "\n",
    "Вычислите точность полученного предсказания. Ответ округлите до трёх знаков после точки-разделителя."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generating predictions...\n",
      "Precision: 0.004523940705554004\n",
      "Rounded Precision: 0.005\n"
     ]
    }
   ],
   "source": [
    "### Решение - Задание 6.5\n",
    "# Prepare test data with true interactions\n",
    "interactions = interactions_test_df.groupby('personId')['contentId'].agg(set).reset_index()\n",
    "interactions.rename(columns={'contentId': 'true_test'}, inplace=True)\n",
    "\n",
    "# Define prediction function\n",
    "def make_prediction(person_id):\n",
    "    # If user is not in the training set, we cannot make predictions using this collaborative filtering approach\n",
    "    if person_id not in users_items_pivot_matrix_df.index:\n",
    "        return []\n",
    "    \n",
    "    # Get similarity row for this user\n",
    "    if person_id in similarity_matrix.index:\n",
    "        user_similarities = similarity_matrix.loc[person_id]\n",
    "    else:\n",
    "        return []\n",
    "\n",
    "    # Step 1: Find users with similarity > 0\n",
    "    similar_users_ids = user_similarities[user_similarities > 0].index\n",
    "    \n",
    "    if len(similar_users_ids) == 0:\n",
    "        return []\n",
    "\n",
    "    # Step 2: Calculate interaction share for each article\n",
    "    # Subset interactions to similar users\n",
    "    similar_users_interactions = users_items_pivot_matrix_df.loc[similar_users_ids]\n",
    "\n",
    "    # Count users who interacted (value > 0)\n",
    "    article_interaction_counts = (similar_users_interactions > 0).sum()\n",
    "\n",
    "    # Calculate share\n",
    "    article_shares = article_interaction_counts / len(similar_users_ids)\n",
    "\n",
    "    # Step 3: Filter out articles the target user has already seen\n",
    "    target_user_seen_mask = users_items_pivot_matrix_df.loc[person_id] > 0\n",
    "    seen_articles = target_user_seen_mask[target_user_seen_mask].index\n",
    "    \n",
    "    # Drop seen articles\n",
    "    recommendations = article_shares.drop(index=seen_articles, errors='ignore')\n",
    "\n",
    "    # Sort descending and take top 10\n",
    "    top_recommendations = recommendations.sort_values(ascending=False).head(10)\n",
    "    \n",
    "    return list(top_recommendations.index)\n",
    "\n",
    "# Apply prediction to all test users\n",
    "# This might take a little bit of time but N=1112 is small\n",
    "from tqdm import tqdm\n",
    "tqdm.pandas()\n",
    "\n",
    "print(\"Generating predictions...\")\n",
    "interactions['prediction'] = interactions['personId'].apply(make_prediction)\n",
    "\n",
    "# Calculate precision\n",
    "def calc_precision(column, df):\n",
    "    return (df.apply(lambda row: len(set(row['true_test']).intersection(\n",
    "                set(row[column]))) / min(len(row['true_test']) + 0.001, 10.0), axis=1)).mean()\n",
    "\n",
    "precision = calc_precision('prediction', interactions)\n",
    "print(f\"Precision: {precision}\")\n",
    "print(f\"Rounded Precision: {precision:.3f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Задание 6.6\n",
    "\n",
    "1 point possible (graded)\n",
    "\n",
    "Теперь реализуем рекомендательную систему с использованием SVD.\n",
    "\n",
    "Разложите матрицу взаимодействий пользователей со статьями с помощью функции svd из модуля scipy. Найдите максимальное значение в получившейся матрице U. Результат округлите до двух знаков после точки-разделителя."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shape of U: (1112, 1112)\n",
      "Max value in U: 0.8585681104884452\n",
      "Rounded Max value in U: 0.86\n"
     ]
    }
   ],
   "source": [
    "### Решение - Задание 6.6\n",
    "# Using scipy.linalg.svd as requested/implied by the reference \"svd(ratings)\"\n",
    "# This performs full SVD on the dense matrix\n",
    "\n",
    "U, sigma, Vt = svd(ratings_matrix)\n",
    "\n",
    "print(f\"Shape of U: {U.shape}\")\n",
    "max_u = np.max(U)\n",
    "print(f\"Max value in U: {max_u}\")\n",
    "print(f\"Rounded Max value in U: {max_u:.2f}\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Значения матрицы с сингулярными числами отсортированы по убыванию. Допустим, мы хотим оставить только первые 100 компонент и получить скрытые представления размерности 100. Для этого необходимо оставить 100 столбцов в матрице U, только первые 100 значений из sigma (и сделать из них диагональную матрицу) и 100 строк в матрице V. Затем необходимо перемножить преобразованные матрицы."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Задание 6.7\n",
    "\n",
    "1 point possible (graded)\n",
    "\n",
    "Найдите сумму всех элементов в новой сингулярной матрице. Ответ округлите до двух знаков после точки-разделителя."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sum of elements in the new singular matrix (top 100 diagonal): 2096.432772165698\n",
      "Rounded Sum: 2096.43\n",
      "Reconstructed Matrix Shape: (1112, 2366)\n"
     ]
    }
   ],
   "source": [
    "### Решение - Задание 6.7\n",
    "k = 100\n",
    "# Берем первые 100 сингулярных чисел из массива sigma\n",
    "s = np.diag(sigma[:k])\n",
    "U_k = U[:, 0:k]\n",
    "Vt_k = Vt[0:k, :]\n",
    "\n",
    "sum_sigma_new = np.sum(s)\n",
    "print(f\"Sum of elements in the new singular matrix (top {k} diagonal): {sum_sigma_new}\")\n",
    "print(f\"Rounded Sum: {sum_sigma_new:.2f}\")\n",
    "\n",
    "# Reconstruct the matrix (ready for next tasks)\n",
    "new_ratings_matrix = np.dot(np.dot(U_k, s), Vt_k)\n",
    "print(f\"Reconstructed Matrix Shape: {new_ratings_matrix.shape}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Теперь мы можем сделать предсказание по полученной матрице.\n",
    "\n",
    "Примечание. Помните, что не нужно учитывать статьи, которые уже были просмотрены пользователем.\n",
    "\n",
    "Найдите для каждого пользователя статьи с наибольшими оценками в восстановленной матрице."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Задание 6.8\n",
    "\n",
    "1 point possible (graded)\n",
    "\n",
    "Вычислите качество полученного предсказания, используя всё ту же метрику точности. Ответ округлите до трёх знаков после точки-разделителя."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generating SVD predictions...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/982 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 982/982 [00:00<00:00, 1906.92it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SVD Precision: 0.0123816552206202\n",
      "Rounded SVD Precision: 0.012\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "### Решение - Задание 6.8\n",
    "# top_k recommendations (ответ сходится с эталонным только при top_k = 8 или top_k = 7)\n",
    "top_k = 8\n",
    "\n",
    "# Wrap reconstructed matrix in DataFrame for easier indexing\n",
    "new_ratings_df = pd.DataFrame(new_ratings_matrix, \n",
    "                              index=users_items_pivot_matrix_df.index, \n",
    "                              columns=users_items_pivot_matrix_df.columns)\n",
    "\n",
    "# Prepare test interactions\n",
    "interactions = interactions_test_df.groupby('personId')['contentId'].agg(set).reset_index()\n",
    "interactions.rename(columns={'contentId': 'true_test'}, inplace=True)\n",
    "\n",
    "def make_prediction_svd(person_id):\n",
    "    if person_id not in new_ratings_df.index:\n",
    "        return []\n",
    "    \n",
    "    # Get user's predicted scores\n",
    "    user_scores = new_ratings_df.loc[person_id]\n",
    "    \n",
    "    # Identify items user has already seen in training\n",
    "    seen_mask = users_items_pivot_matrix_df.loc[person_id] > 0\n",
    "    seen_articles = seen_mask[seen_mask].index\n",
    "    \n",
    "    # Exclude seen articles\n",
    "    user_scores_excluded = user_scores.drop(index=seen_articles, errors='ignore')\n",
    "    \n",
    "    # Take top = top_k recommendations\n",
    "    \n",
    "    top_recommendations = user_scores_excluded.sort_values(ascending=False).head(top_k)\n",
    "    \n",
    "    return list(top_recommendations.index)\n",
    "\n",
    "# Generate predictions\n",
    "tqdm.pandas()\n",
    "print(\"Generating SVD predictions...\")\n",
    "interactions['prediction_svd'] = interactions['personId'].progress_apply(make_prediction_svd)\n",
    "\n",
    "# Calculate precision\n",
    "def calc_precision(column, df):\n",
    "    return (df.apply(lambda row: len(set(row['true_test']).intersection(\n",
    "                set(row[column]))) / min(len(row['true_test']) + 0.001, 10.0), axis=1)).mean()\n",
    "\n",
    "precision_svd = calc_precision('prediction_svd', interactions)\n",
    "print(f\"SVD Precision: {precision_svd}\")\n",
    "print(f\"Rounded SVD Precision: {precision_svd:.3f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Эталонный ответ 0,012"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Итак, мы реализовали два алгоритма коллаборативной фильтрации буквально с нуля! Теперь для полноты картины давайте реализуем на этих данных гибридную модель и посмотрим, какое качество получится. Для этого воспользуемся уже изученной библиотекой LightFM.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Задание 6.9\n",
    "\n",
    "1 point possible (graded)\n",
    "\n",
    "Возьмите матрицу, подготовленную в задании 6.1. Преобразуйте её в разреженную матрицу:\n",
    "\n",
    "from scipy.sparse import csr_matrix\n",
    "ratings_matrix = csr_matrix(ratings)\n",
    "Воспользовавшись функцией random_train_test_split() из библиотеки lightfm, разделите данные на валидационную и обучающую выборки в соотношении 1:2 (30% на валидационную выборку, 70% на обучающую). В качестве значения параметра random_state возьмите число 13.\n",
    "\n",
    "Обучите модель LightFM со 100 компонентами, параметром random_state = 13, темпом обучения 0.05 и функцией потерь 'warp'. Обратите внимание на то, что так как в данном случае у нас нет item-признаков, то параметр item_features задавать не нужно.\n",
    "\n",
    "Вычислите показатель точности (precision@k) при k = 10. Ответ округлите до двух знаков после точки-разделителя."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LightFM Precision@10: 0.028684470802545547\n",
      "Rounded LightFM Precision@10: 0.03\n"
     ]
    }
   ],
   "source": [
    "### Решение - Задание 6.9\n",
    "\n",
    "from scipy.sparse import csr_matrix\n",
    "from lightfm import LightFM\n",
    "from lightfm.cross_validation import random_train_test_split\n",
    "from lightfm.evaluation import precision_at_k\n",
    "\n",
    "# 1. Sparse Matrix\n",
    "ratings_matrix_sparse = csr_matrix(users_items_pivot_matrix_df.values)\n",
    "\n",
    "# 2. Split (30% validation, 70% train)\n",
    "train_data, test_data = random_train_test_split(ratings_matrix_sparse, test_percentage=0.3, random_state=13)\n",
    "\n",
    "# 3. Model\n",
    "model = LightFM(learning_rate=0.05, loss='warp', no_components=100, random_state=13)\n",
    "\n",
    "# 4. Train (epochs=10 is assumed standard if not specified, often sufficient for exercises)\n",
    "model.fit(train_data, epochs=10)\n",
    "\n",
    "# 5. Evaluate\n",
    "precision_score = precision_at_k(model, test_data, k=10).mean()\n",
    "\n",
    "print(f\"LightFM Precision@10: {precision_score}\")\n",
    "print(f\"Rounded LightFM Precision@10: {precision_score:.2f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "В данном случае модель «из коробки» показала наилучший результат, однако это совсем не показатель того, что стоит пользоваться исключительно готовыми функциями. Зная тонкости работы алгоритмов, вы можете создавать собственные гибридные системы, настраивать отдельные алгоритмы и добиваться ещё лучших результатов."
   ]
  }
 ],
 "metadata": {
  "colab": {
   "provenance": []
  },
  "kernelspec": {
   "display_name": "DS_py311_gpu",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
