{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "c353de9a",
   "metadata": {},
   "source": [
    "# Проект: классификация"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4a6e54dc",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from  sklearn.ensemble import IsolationForest\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "from sklearn.preprocessing  import LabelEncoder\n",
    "from sklearn import linear_model \n",
    "from sklearn import tree \n",
    "from sklearn import ensemble \n",
    "from sklearn import metrics \n",
    "from sklearn import preprocessing \n",
    "from sklearn.model_selection import train_test_split \n",
    "from sklearn.feature_selection import SelectKBest, f_classif\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.ensemble import GradientBoostingClassifier\n",
    "from sklearn.ensemble import StackingClassifier\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "import optuna\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.metrics import make_scorer, f1_score\n",
    "\n",
    "\n",
    "import plotly\n",
    "import plotly.express as px\n",
    "import plotly.io as pio\n",
    "#pio.renderers.default = \"notebook_connected\"\n",
    "#pio.renderers.default = \"notebook\"  # для интерактивных графиков\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5ca8e0e6",
   "metadata": {},
   "outputs": [],
   "source": [
    "#!pip install --upgrade plotly"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "71559b60",
   "metadata": {},
   "source": [
    "## Часть 1. Знакомство с данными, обработка пропусков и выбросов"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7c5e31b2",
   "metadata": {},
   "source": [
    "### Задание 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "20730cd7",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('data/bank_fin.csv', sep = ';')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ba11dc67",
   "metadata": {},
   "outputs": [],
   "source": [
    "# исследуйте данные на предмет пропусков. Где есть пропущенные значения? Сколько их?\n",
    "# ваш код\n",
    "missing_values = df.isnull().sum().sort_values()\n",
    "\n",
    "# Фильтруем только ненулевые значения\n",
    "non_zero_missing = missing_values[missing_values > 0]\n",
    "\n",
    "print(non_zero_missing)\n",
    "\n",
    "# balance    25"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6366f059",
   "metadata": {},
   "source": [
    "### Задание 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "98ea29d4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# есть ли в признаке job пропущенные значения? Возможно, они обозначены каким-то специальным словом?\n",
    "# ваш код\n",
    "df['job'].value_counts()\n",
    "\n",
    "# unknown            70"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8fcf4fcd",
   "metadata": {},
   "source": [
    "### Задание 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3a01be5e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# преобразуйте признак balance таким образом, чтобы он корректно считывался, как вещественное число (float)\n",
    "# ваш код\n",
    "display(df['balance'].head())\n",
    "\n",
    "# Удаляем пробелы, символы валюты и заменяем запятую на точку\n",
    "#df['balance'] = df['balance'].str.replace(' ', '').str.replace('$', '').str.replace(',', '.')\n",
    "df['balance'] = df['balance'].apply(lambda x: x if [x]==[np.nan] else float((x.replace(' ', '')).replace(',', '.').split('$')[0]))\n",
    "\n",
    "# Преобразуем в float\n",
    "df['balance'] = df['balance'].astype(float)\n",
    "\n",
    "display(df['balance'].head())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "08fc1f79",
   "metadata": {},
   "outputs": [],
   "source": [
    "display(f'Среднее значение balance: {df[\"balance\"].mean():.3f}')\n",
    "# Среднее значение balance: 1529.129"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6de63fd7",
   "metadata": {},
   "source": [
    "### Задание 4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6a684a63",
   "metadata": {},
   "outputs": [],
   "source": [
    "# обработайте пропуски в признаки balance , заменив их на медианные значения по данному признаку\n",
    "# ваш код\n",
    "df['balance'] = df['balance'].fillna(df['balance'].median())\n",
    "\n",
    "display(f'Среднее значение balance: {df[\"balance\"].mean():.3f}')\n",
    "# Среднее значение balance: 1526.936\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1097ec42",
   "metadata": {},
   "source": [
    "### Задание 5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0fa070a6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# обработайте пропуски в категориальных признаках: job и education, заменив их на модальные значения\n",
    "# ваш код\n",
    "\n",
    "display(df['job'].value_counts())\n",
    "display(df['education'].value_counts())\n",
    "\n",
    "\n",
    "df['job'] = df['job'].replace('unknown', df['job'].mode()[0])\n",
    "df['education'] = df['education'].replace('unknown', df['education'].mode()[0])\n",
    "\n",
    "# Найти самую популярную работу\n",
    "most_popular_job = df['job'].mode()[0]\n",
    "\n",
    "# Найти самый популярный уровень образования\n",
    "most_popular_education = df['education'].mode()[0]\n",
    "\n",
    "# Отфильтровать клиентов с самой популярной работой и образованием\n",
    "filtered_clients = df[(df['job'] == most_popular_job) & (df['education'] == most_popular_education)]\n",
    "\n",
    "# Рассчитать средний баланс\n",
    "average_balance = filtered_clients['balance'].mean()\n",
    "\n",
    "print(f\"Средний баланс для клиентов с самой популярной работой ({most_popular_job}) и образованием ({most_popular_education}):  {average_balance:.3f}\")\n",
    "\n",
    "# Средний баланс для клиентов с самой популярной работой (management) и образованием (secondary):  1598.883"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "02af77c6",
   "metadata": {},
   "source": [
    "### Задание 6"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3802cdd9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# удалите все выбросы для признака balance\n",
    "\n",
    "# ваш код\n",
    "\n",
    "# Вычисляем квартили\n",
    "Q1 = df['balance'].quantile(0.25)\n",
    "Q3 = df['balance'].quantile(0.75)\n",
    "\n",
    "# Рассчитываем интерквартильный размах\n",
    "IQR = Q3 - Q1\n",
    "\n",
    "# Определяем границы выбросов\n",
    "lower_bound = Q1 - 1.5 * IQR\n",
    "upper_bound = Q3 + 1.5 * IQR\n",
    "\n",
    "# Округляем границы до целых чисел\n",
    "lower_bound = round(lower_bound)\n",
    "upper_bound = round(upper_bound)\n",
    "\n",
    "print(f\"Нижняя граница: {lower_bound}, Верхняя граница: {upper_bound}\")\n",
    "\n",
    "# Фильтруем данные, удаляя выбросы\n",
    "df_filtered = df[(df['balance'] >= lower_bound) & (df['balance'] <= upper_bound)]\n",
    "\n",
    "# Проверяем результат\n",
    "display(df_filtered.info())\n",
    "display(df_filtered.shape)\n",
    "\n",
    "# Нижняя граница: -2241, Верхняя граница: 4063"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5d22b8cd",
   "metadata": {},
   "source": [
    "## Часть 2:  Разведывательный анализ"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "21e1f083",
   "metadata": {},
   "source": [
    "### Задание 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6d0cd3a8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# изучите соотношение классов в ваших данных на предмет несбалансированности, проиллюстрируйте результат\n",
    "# ваш код\n",
    "\n",
    "pio.renderers.default = \"notebook\" \n",
    "fig = px.histogram(df_filtered, x='deposit', title='Deposit Distribution', text_auto=True)\n",
    "fig.show()\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "229a0da5",
   "metadata": {},
   "source": [
    "Классы относительно сбалансированы."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "426b1d40",
   "metadata": {},
   "source": [
    "### Задания 2 и 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "603cdb3c",
   "metadata": {},
   "outputs": [],
   "source": [
    "#рассчитайте описательные статистики для количественных переменных, проинтерпретируйте результат\n",
    "#ваш код\n",
    "\n",
    "# Предположим, что df - ваш DataFrame\n",
    "quantitative_columns = df_filtered.select_dtypes(include=['float64', 'int64']).columns\n",
    "\n",
    "# Получаем описательные статистики\n",
    "descriptive_stats = df_filtered[quantitative_columns].describe()\n",
    "display(descriptive_stats)\n",
    "\n",
    "# Визуализация распределений с помощью Plotly\n",
    "for column in quantitative_columns:\n",
    "    fig = px.histogram(df, x=column, title=f'Distribution of {column}', marginal='box', nbins=30)\n",
    "    fig.update_layout(bargap=0.1)\n",
    "    fig.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "524bb616",
   "metadata": {},
   "source": [
    "\n",
    "На основании полученных описательных статистик для количественных переменных можно сделать следующие выводы:\n",
    "------\n",
    "\n",
    "1. Возраст (age)\n",
    "Среднее значение: 40.90 года, что указывает на то, что большинство клиентов находятся в среднем возрасте.\n",
    "Стандартное отклонение: 11.73, что говорит о значительной вариативности возрастов.\n",
    "Минимум и максимум: Возраст варьируется от 18 до 95 лет, что охватывает широкий возрастной диапазон.\n",
    "Квартильный размах: 25% клиентов моложе 32 лет, а 75% моложе 48 лет, что указывает на концентрацию клиентов в диапазоне 32-48 лет.\n",
    "\n",
    "2. Баланс (balance)\n",
    "Среднее значение: 807.65, но с высоким стандартным отклонением 994.15, что указывает на значительную вариативность.\n",
    "Минимум и максимум: Баланс варьируется от -2049 до 4063, что указывает на наличие как отрицательных, так и высоких значений.\n",
    "Квартильный размах: 25% клиентов имеют баланс ниже 95, а 75% ниже 1227, что указывает на асимметрию в распределении.\n",
    "\n",
    "3. День (day)\n",
    "Среднее значение: 15.59, что указывает на средний день месяца, когда происходят транзакции.\n",
    "Стандартное отклонение: 8.44, что говорит о равномерном распределении транзакций в течение месяца.\n",
    "Минимум и максимум: Транзакции происходят в диапазоне от 1 до 31 дня.\n",
    "\n",
    "4. Длительность (duration)\n",
    "Среднее значение: 368.74 секунд, что указывает на среднюю длительность взаимодействия.\n",
    "Стандартное отклонение: 346.65, что говорит о значительной вариативности.\n",
    "Минимум и максимум: Длительность варьируется от 2 до 3881 секунд, что указывает на наличие как очень коротких, так и очень длинных взаимодействий.\n",
    "\n",
    "5. Кампания (campaign)\n",
    "Среднее значение: 2.52, что указывает на среднее количество контактов в кампании.\n",
    "Стандартное отклонение: 2.71, что говорит о значительной вариативности.\n",
    "Минимум и максимум: Количество контактов варьируется от 1 до 43, что указывает на наличие как единичных, так и многократных контактов.\n",
    "\n",
    "6. Дни с последнего контакта (pdays)\n",
    "Среднее значение: 51.32, но с высоким стандартным отклонением 109.64, что указывает на значительную вариативность.\n",
    "Минимум и максимум: Значения варьируются от -1 (никогда не контактировали) до 854 дней.\n",
    "Квартильный размах: Большинство значений -1, что указывает на редкие повторные контакты.\n",
    "\n",
    "7. Предыдущие контакты (previous)\n",
    "Среднее значение: 0.82, что указывает на редкие предыдущие контакты.\n",
    "Стандартное отклонение: 2.24, что говорит о значительной вариативности.\n",
    "Минимум и максимум: Количество предыдущих контактов варьируется от 0 до 58.\n",
    "\n",
    "Общие выводы:\n",
    "- Вариативность: Высокое стандартное отклонение в переменных balance, duration, и pdays указывает на значительную вариативность и наличие выбросов.\n",
    "- Аномалии: Наличие отрицательных значений в balance и pdays может указывать на аномалии или специфические условия данных.\n",
    "- Распределение: Средние значения и медианы (50%) в некоторых переменных значительно различаются, что может указывать на асимметрию в распределении данных.\n",
    "\n",
    "Визуализация:\n",
    "- Гистограммы: Могут помочь визуально оценить распределение данных и выявить выбросы.\n",
    "- Боксплоты: Полезны для выявления выбросов и оценки симметрии распределения.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "821dc39e",
   "metadata": {},
   "source": [
    "### Задания 4 и 5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bf45afc9",
   "metadata": {},
   "outputs": [],
   "source": [
    "#рассчитайте описательные статистики для категориальных переменных, проинтерпретируйте результат\n",
    "#ваш код\n",
    "#постройте визуализации, иллюстрирующие результаты\n",
    "\n",
    "import math\n",
    "\n",
    "categorical_columns = df_filtered.select_dtypes(include=['object']).columns\n",
    "\n",
    "display(df_filtered[categorical_columns].describe())\n",
    "\n",
    "# Получаем описательные статистики для категориальных переменных\n",
    "for column in categorical_columns:\n",
    "    print(f\"Статистика для {column}:\")\n",
    "    value_counts_df = df_filtered[column].value_counts().to_frame().reset_index()\n",
    "    value_counts_df.columns = [column, 'count']  # Переименовываем столбцы\n",
    "    display(value_counts_df)\n",
    "    print(\"\\n\")\n",
    "\n",
    "# Определяем количество строк и столбцов для подграфиков\n",
    "num_columns = len(categorical_columns)\n",
    "num_rows = math.ceil(num_columns / 3)\n",
    "\n",
    "# Визуализация распределений\n",
    "plt.figure(figsize=(15, 5 * num_rows))\n",
    "for i, column in enumerate(categorical_columns, 1):\n",
    "    plt.subplot(num_rows, 3, i)\n",
    "    sns.countplot(y=df_filtered[column], order=df_filtered[column].value_counts().index)\n",
    "    plt.title(column)\n",
    "    plt.xlabel('Count')\n",
    "    plt.ylabel(column)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e3ed1def",
   "metadata": {},
   "source": [
    "На основании предоставленной описательной статистики для категориальных переменных можно сделать следующие выводы:\n",
    "------\n",
    "1. Работа (job)\n",
    "Уникальные значения: 11 различных категорий работы.\n",
    "Наиболее частая категория: \"management\" с частотой 2315, что указывает на то, что большинство клиентов работают в управлении.\n",
    "\n",
    "2. Семейное положение (marital)\n",
    "Уникальные значения: 3 категории (например, \"married\", \"single\", \"divorced\").\n",
    "Наиболее частая категория: \"married\" с частотой 5715, что указывает на то, что большинство клиентов состоят в браке.\n",
    "\n",
    "3. Образование (education)\n",
    "Уникальные значения: 3 категории (например, \"primary\", \"secondary\", \"tertiary\").\n",
    "Наиболее частая категория: \"secondary\" с частотой 5517, что указывает на то, что большинство клиентов имеют среднее образование.\n",
    "\n",
    "4. Наличие дефолта (default)\n",
    "Уникальные значения: 2 категории (\"yes\", \"no\").\n",
    "Наиболее частая категория: \"no\" с частотой 9939, что указывает на то, что большинство клиентов не имеют дефолта.\n",
    "\n",
    "5. Наличие жилья (housing)\n",
    "Уникальные значения: 2 категории (\"yes\", \"no\").\n",
    "Наиболее частая категория: \"no\" с частотой 5243, что указывает на то, что у большинства клиентов нет жилья.\n",
    "\n",
    "6. Наличие кредита (loan)\n",
    "Уникальные значения: 2 категории (\"yes\", \"no\").\n",
    "Наиболее частая категория: \"no\" с частотой 8712, что указывает на то, что у большинства клиентов нет кредита.\n",
    "\n",
    "7. Контакт (contact)\n",
    "Уникальные значения: 3 категории (например, \"cellular\", \"telephone\", \"unknown\").\n",
    "Наиболее частая категория: \"cellular\" с частотой 7283, что указывает на то, что большинство контактов осуществляется через мобильные телефоны.\n",
    "\n",
    "8. Месяц (month)\n",
    "Уникальные значения: 12 месяцев.\n",
    "Наиболее частая категория: \"may\" с частотой 2617, что указывает на то, что большинство контактов происходят в мае.\n",
    "\n",
    "9. Исход предыдущей кампании (poutcome)\n",
    "Уникальные значения: 4 категории (например, \"success\", \"failure\", \"other\", \"unknown\").\n",
    "Наиболее частая категория: \"unknown\" с частотой 7570, что указывает на то, что для большинства клиентов исход предыдущей кампании неизвестен.\n",
    "\n",
    "10. Депозит (deposit)\n",
    "Уникальные значения: 2 категории (\"yes\", \"no\").\n",
    "Наиболее частая категория: \"no\" с частотой 5424, что указывает на то, что большинство клиентов не открыли депозит.\n",
    "\n",
    "**Общие выводы:**\n",
    "\n",
    "- Дисбаланс категорий: В некоторых переменных, таких как default, housing, и loan, наблюдается значительный дисбаланс, где одна категория доминирует.\n",
    "- Неизвестные значения: В переменной poutcome значительная часть данных имеет значение \"unknown\", что может указывать на недостаток информации или проблемы с данными.\n",
    "- Преобладание определенных категорий: В переменных job, marital, и education наблюдается преобладание определенных категорий, что может быть полезно для сегментации клиентов.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "472cff5b",
   "metadata": {},
   "source": [
    "### Задание 6"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2d640ce1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Узнайте, для какого статуса предыдущей маркетинговой кампании успех в текущей превалирует над количеством неудач.\n",
    "# ваш код\n",
    "\n",
    "# Сгруппируем данные по 'poutcome' и посчитаем количество значений 'deposit'\n",
    "poutcome_deposit_counts = df_filtered.groupby('poutcome')['deposit'].value_counts().unstack()\n",
    "\n",
    "# Выведем результат\n",
    "display(poutcome_deposit_counts)\n",
    "\n",
    "# Найдем статус, для которого успехов больше, чем неудач\n",
    "successful_poutcome = poutcome_deposit_counts[poutcome_deposit_counts['yes'] > poutcome_deposit_counts['no']]\n",
    "\n",
    "display(\"Статус предыдущей кампании, для которого успехов больше, чем неудач:\")\n",
    "display(successful_poutcome)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9c32e3aa",
   "metadata": {},
   "source": [
    "### Задание 7"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "df437ec3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# узнайте, в каком месяце чаще всего отказывались от предложения открыть депозит\n",
    "# ваш код\n",
    "\n",
    "# Сгруппируем данные по 'month' и посчитаем количество отказов ('deposit' = 'no')\n",
    "month_deposit_counts = df_filtered[df_filtered['deposit'] == 'no']['month'].value_counts()\n",
    "\n",
    "# Выведем результат\n",
    "display(month_deposit_counts)\n",
    "\n",
    "# Найдем месяц с наибольшим количеством отказов\n",
    "most_declined_month = month_deposit_counts.idxmax()\n",
    "\n",
    "display(f\"Месяц, в котором чаще всего отказывались от предложения открыть депозит: {most_declined_month}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5f20762f",
   "metadata": {},
   "source": [
    "### Задание 8"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "95d56f1b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# создайте возрастные группы и определите, в каких группах более склонны открывать депозит, чем отказываться от предложения\n",
    "# ваш код\n",
    "\n",
    "# Определяем границы и метки для категорий\n",
    "bins = [0, 30, 40, 50, 60, float('inf')]\n",
    "labels = ['<30', '30-40', '40-50', '50-60', '60+']\n",
    "\n",
    "# Преобразуем возраст в категории\n",
    "df_filtered['age_group'] = pd.cut(df_filtered['age'], bins=bins, labels=labels, right=False)\n",
    "\n",
    "# Создаем сводную таблицу для анализа\n",
    "pivot_table = df_filtered.pivot_table(index='age_group', columns='deposit', aggfunc='size', fill_value=0)\n",
    "\n",
    "# Выводим сводную таблицу\n",
    "display(pivot_table)\n",
    "\n",
    "# Построим диаграмму для визуализации различий\n",
    "fig = px.histogram(\n",
    "    df_filtered, \n",
    "    x='age_group', \n",
    "    color='deposit', \n",
    "    category_orders={'age_group': ['<30', '30-40', '40-50', '50-60', '60+']},\n",
    "    barmode='group',\n",
    "    title='Количество открытых/не открытых депозитов по возрастным группам',\n",
    "    labels={'age_group': 'Возрастная группа', 'count': 'Количество'}\n",
    ")\n",
    "\n",
    "fig.update_layout(\n",
    "    xaxis_title='Возрастная группа',\n",
    "    yaxis_title='Количество',\n",
    "    legend_title='Депозит'\n",
    ")\n",
    "\n",
    "fig.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0841c685",
   "metadata": {},
   "source": [
    "### Задания 9 и 10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0d84a9e1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# постройте визуализации для открывших и неоткрывших депозит в зависимости от семейного статуса\n",
    "fig_marital = px.histogram(\n",
    "    df_filtered, \n",
    "    x='marital', \n",
    "    color='deposit', \n",
    "    barmode='group',\n",
    "    title='Количество открытых/не открытых депозитов по семейному положению',\n",
    "    labels={'marital': 'Семейное положение', 'count': 'Количество'}\n",
    ")\n",
    "\n",
    "fig_marital.update_layout(\n",
    "    xaxis_title='Семейное положение',\n",
    "    yaxis_title='Количество',\n",
    "    legend_title='Депозит'\n",
    ")\n",
    "\n",
    "fig_marital.show()\n",
    "\n",
    "# Текстовый вывод\n",
    "marital_counts = df_filtered.groupby('marital')['deposit'].value_counts().unstack()\n",
    "display(\"Распределение депозитов по семейному положению:\")\n",
    "display(marital_counts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "16333967",
   "metadata": {},
   "outputs": [],
   "source": [
    "# постройте визуализации для открывших и неоткрывших депозит в зависимости от образования\n",
    "fig_education = px.histogram(\n",
    "    df_filtered, \n",
    "    x='education', \n",
    "    color='deposit', \n",
    "    barmode='group',\n",
    "    title='Количество открытых/не открытых депозитов по уровню образования',\n",
    "    labels={'education': 'Уровень образования', 'count': 'Количество'}\n",
    ")\n",
    "\n",
    "fig_education.update_layout(\n",
    "    xaxis_title='Уровень образования',\n",
    "    yaxis_title='Количество',\n",
    "    legend_title='Депозит'\n",
    ")\n",
    "\n",
    "fig_education.show()\n",
    "\n",
    "# Текстовый вывод\n",
    "education_counts = df_filtered.groupby('education')['deposit'].value_counts().unstack()\n",
    "display(\"Распределение депозитов по уровню образования:\")\n",
    "display(education_counts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "738224f8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# постройте визуализации для открывших и неоткрывших депозит в зависимости от вида профессиональной занятости\n",
    "fig_job = px.histogram(\n",
    "    df_filtered, \n",
    "    x='job', \n",
    "    color='deposit', \n",
    "    barmode='group',\n",
    "    title='Количество открытых/не открытых депозитов по сфере занятости',\n",
    "    labels={'job': 'Сфера занятости', 'count': 'Количество'}\n",
    ")\n",
    "\n",
    "fig_job.update_layout(\n",
    "    xaxis_title='Сфера занятости',\n",
    "    yaxis_title='Количество',\n",
    "    legend_title='Депозит'\n",
    ")\n",
    "\n",
    "fig_job.show()\n",
    "\n",
    "# Текстовый вывод\n",
    "job_counts = df_filtered.groupby('job')['deposit'].value_counts().unstack()\n",
    "display(\"Распределение депозитов по сфере занятости:\")\n",
    "display(job_counts)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a521e204",
   "metadata": {},
   "source": [
    "### Задание 11"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "35ab0413",
   "metadata": {},
   "outputs": [],
   "source": [
    "# постройте сводную таблицу, чтобы определить люди с каким образованием и семейным статусом наиболее многочисленны\n",
    "#(если рассматривать тех, кто открыл депозит)\n",
    "\n",
    "# Разделяем таблицу на две части\n",
    "df_deposit_yes = df_filtered[df_filtered['deposit'] == 'yes']\n",
    "df_deposit_no = df_filtered[df_filtered['deposit'] == 'no']\n",
    "\n",
    "\n",
    "# Создаем сводные таблицы\n",
    "pivot_yes = df_deposit_yes.pivot_table(index='education', columns='marital', aggfunc='size', fill_value=0)\n",
    "pivot_no = df_deposit_no.pivot_table(index='education', columns='marital', aggfunc='size', fill_value=0)\n",
    "\n",
    "# Тепловая карта для тех, кто открыл депозит\n",
    "plt.figure(figsize=(10, 6))\n",
    "sns.heatmap(pivot_yes, annot=True, fmt=\"d\", cmap=\"coolwarm\")\n",
    "plt.title('Тепловая карта: Открыли депозит')\n",
    "plt.xlabel('Семейное положение')\n",
    "plt.ylabel('Уровень образования')\n",
    "plt.show()\n",
    "\n",
    "# Находим пересечение с максимальным значением в pivot_yes\n",
    "max_value = pivot_yes.max().max()\n",
    "max_location = pivot_yes.stack().idxmax()\n",
    "\n",
    "# Выводим результат в виде текста\n",
    "display(f\"Самое многочисленное пересечение Открывших депозит: {max_location} с количеством {max_value}\")\n",
    "\n",
    "\n",
    "# Тепловая карта для тех, кто не открыл депозит\n",
    "plt.figure(figsize=(10, 6))\n",
    "sns.heatmap(pivot_no, annot=True, fmt=\"d\", cmap=\"coolwarm\")\n",
    "plt.title('Тепловая карта: Не открыли депозит')\n",
    "plt.xlabel('Семейное положение')\n",
    "plt.ylabel('Уровень образования')\n",
    "plt.show()\n",
    "\n",
    "# Находим пересечение с максимальным значением в pivot_yes\n",
    "max_value_no = pivot_no.max().max()\n",
    "max_location_no = pivot_no.stack().idxmax()\n",
    "\n",
    "# Выводим результат в виде текста\n",
    "display(f\"Самое многочисленное пересечение Не открывших депозит: {max_location_no} с количеством {max_value_no}\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dfd805c0",
   "metadata": {},
   "source": [
    "## Часть 3: преобразование данных"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e44e715b",
   "metadata": {},
   "source": [
    "### Задание 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1e815773",
   "metadata": {},
   "outputs": [],
   "source": [
    "# преобразуйте уровни образования\n",
    "\n",
    "# Создаем экземпляр LabelEncoder\n",
    "label_encoder = LabelEncoder()\n",
    "\n",
    "# Преобразуем категориальный признак 'education'\n",
    "df_filtered['education'] = label_encoder.fit_transform(df_filtered['education'])\n",
    "\n",
    "# Выводим первые несколько строк, чтобы проверить результат\n",
    "display(f'Сумма значений education после преобразования LabelEncoder: {df_filtered[\"education\"].sum()}')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e7feb0d4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Преобразуем категориальный признак 'age_group'\n",
    "df_filtered['age_group'] = label_encoder.fit_transform(df_filtered['age_group'])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8c93e73d",
   "metadata": {},
   "source": [
    "### Задания 2 и 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "626a5762",
   "metadata": {},
   "outputs": [],
   "source": [
    "# преобразуйте бинарные переменные в представление из нулей и единиц\n",
    "\n",
    "# Перекодируем переменную 'deposit'\n",
    "df_filtered['deposit'] = df_filtered['deposit'].map({'yes': 1, 'no': 0})\n",
    "\n",
    "# Выводим стандартное отклонение по преобразованной переменной 'deposit'\n",
    "display(f\"Стандартное отклонение по преобразованной переменной 'deposit': {df_filtered['deposit'].std():.3f}\")\n",
    "\n",
    "# Перекодируем переменную 'default'\n",
    "df_filtered['default'] = df_filtered['default'].map({'yes': 1, 'no': 0})\n",
    "\n",
    "# Выводим стандартное отклонение по преобразованной переменной 'default'\n",
    "display(f\"Стандартное отклонение по преобразованной переменной 'default': {df_filtered['default'].std():.3f}\")\n",
    "\n",
    "# Перекодируем переменную 'housing'\n",
    "df_filtered['housing'] = df_filtered['housing'].map({'yes': 1, 'no': 0})\n",
    "\n",
    "# Выводим стандартное отклонение по преобразованной переменной 'housing'\n",
    "display(f\"Стандартное отклонение по преобразованной переменной 'housing': {df_filtered['housing'].std():.3f}\")\n",
    "\n",
    "# Перекодируем переменную 'loan'\n",
    "df_filtered['loan'] = df_filtered['loan'].map({'yes': 1, 'no': 0})\n",
    "\n",
    "# Выводим стандартное отклонение по преобразованной переменной 'loan'\n",
    "display(f\"Стандартное отклонение по преобразованной переменной 'loan': {df_filtered['loan'].std():.3f}\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "02166878",
   "metadata": {},
   "outputs": [],
   "source": [
    "avg_summ_encoded =  df_filtered['default'].mean()+ df_filtered['housing'].mean()+ df_filtered['loan'].mean()\n",
    "\n",
    "display(f'Стандартное отклонение по сумме преобразованных переменных \"default\", \"housing\", \"loan\": {avg_summ_encoded:.3f}')\n",
    "# Стандартное отклонение по сумме преобразованных переменных \"default\", \"housing\", \"loan\": 0.635"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c40dc02a",
   "metadata": {},
   "source": [
    "### Задание 4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b996883f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# создайте дамми-переменные\n",
    "\n",
    "# Список номинальных переменных для преобразования\n",
    "nominal_variables = ['job', 'marital', 'contact', 'month', 'poutcome']\n",
    "\n",
    "# Создаем dummy-переменные\n",
    "df_dummies = (pd.get_dummies(df_filtered[nominal_variables], drop_first=False)).astype(int)\n",
    "\n",
    "# Добавляем dummy-переменные в исходный DataFrame\n",
    "df_with_dummies = pd.concat([df_filtered, df_dummies], axis=1)\n",
    "\n",
    "# Выводим первые несколько строк, чтобы проверить результат\n",
    "display(df_with_dummies.head())\n",
    "display(df_with_dummies.info())\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9a23e318",
   "metadata": {},
   "source": [
    "### Задания 5 и 6"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1c884c1a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# постройте корреляционную матрицу и оцените данные на предмет наличия мультиколлинеарности\n",
    "\n",
    "numeric_columns = df_with_dummies.select_dtypes(include=['number'])\n",
    "\n",
    "# Вычисляем матрицу корреляций для числовых столбцов\n",
    "correlation_matrix = numeric_columns.corr()\n",
    "\n",
    "# Построим тепловую карту\n",
    "plt.figure(figsize=(15, 10))\n",
    "sns.heatmap(correlation_matrix, annot=False, cmap='coolwarm', fmt=\".2f\")\n",
    "plt.title('Матрица корреляций')\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "21a6857c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Извлекаем корреляции с целевой переменной 'deposit_encoded'\n",
    "correlation_with_target = correlation_matrix['deposit'].drop('deposit')\n",
    "\n",
    "# Сортируем корреляции\n",
    "sorted_correlation = correlation_with_target.sort_values()\n",
    "\n",
    "# Создаем DataFrame из отсортированных коэффициентов корреляции\n",
    "correlation_df = sorted_correlation.reset_index()\n",
    "correlation_df.columns = ['Feature', 'Correlation']\n",
    "\n",
    "# Построим столбчатую диаграмму с помощью Plotly\n",
    "fig = px.bar(\n",
    "    correlation_df, \n",
    "    x='Correlation', \n",
    "    y='Feature', \n",
    "    orientation='h', \n",
    "    title='Коэффициенты корреляции с целевой переменной',\n",
    "    labels={'Correlation': 'Коэффициент корреляции', 'Feature': 'Признаки'},\n",
    "    color='Correlation',\n",
    "    color_continuous_scale='Blues'\n",
    ")\n",
    "\n",
    "fig.update_layout(\n",
    "    xaxis_title='Коэффициент корреляции',\n",
    "    yaxis_title='Признаки',\n",
    "    yaxis={'categoryorder':'total ascending'}\n",
    ")\n",
    "\n",
    "fig.show()\n",
    "display('Коэффициенты корреляции с целевой переменной')\n",
    "display(sorted_correlation)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "139c41b9",
   "metadata": {},
   "source": [
    "Мультиколлинеарность признаков отсутсвует. \n",
    "\n",
    "Признаки имеющие наибольшую корреляцию с целевой переменной:\n",
    "- продолжительность контакта в секундах (duration)\n",
    "- успех результата прошлой маркетинговой кампании (poutcome_success)\n",
    "- контакт с клиентом по сотовому (contact_cellular)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b5b4c1a5",
   "metadata": {},
   "source": [
    "### Задания 7 и 8"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e6c964af",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_with_dummies.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "79f3e432",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df_with_dummies.drop(columns=['age', 'education', 'default', 'loan', 'housing'])\n",
    "\n",
    "df = df.select_dtypes(include=['number'])\n",
    "#df = df_with_dummies.copy()\n",
    "\n",
    "X = df.drop(['deposit'], axis=1)\n",
    "y = df['deposit']\n",
    " \n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, stratify=y, random_state = 42, test_size = 0.33)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e3a097a4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# рассчитайте необходимые показатели\n",
    "\n",
    "# Размеры выборки\n",
    "display(f'Размер тренировочной выборки X_train={X_train.shape}, y_train={y_train.shape[0]}')\n",
    "display(f'Размер тестовой выборки X_test={X_test.shape}, y_test={y_test.shape[0]}')\n",
    "\n",
    "# Вычисляем среднее значение целевой переменной на тестовой выборке\n",
    "display(f\"Среднее значение целевой переменной на тестовой выборке: {y_test.mean():.2f}\")\n",
    "\n",
    "# 'Размер тренировочной выборки X_train=(6770, 39), y_train=6770'\n",
    "# 'Размер тестовой выборки X_test=(3335, 39), y_test=3335'\n",
    "# 'Среднее значение целевой переменной на тестовой выборке: 0.46'"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2e381a4f",
   "metadata": {},
   "source": [
    "### Задание 9"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0f6e03e0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# с помощью SelectKBest отберите 15 наиболее подходящих признаков\n",
    "\n",
    "selector = SelectKBest(score_func=f_classif, k=15)\n",
    "X_train_selected = selector.fit_transform(X_train, y_train)\n",
    "\n",
    "# Получаем имена отобранных признаков\n",
    "selected_features = X_train.columns[selector.get_support()]\n",
    "\n",
    "selector.get_feature_names_out()\n",
    "selector_col = list(selector.get_feature_names_out())\n",
    "\n",
    "# Выводим отобранные признаки\n",
    "display(\"Отобранные признаки:\", selector_col)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "60132ef3",
   "metadata": {},
   "source": [
    "### Задание 10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e91b06f3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# нормализуйте данные с помощью minmaxsxaler\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "\n",
    "# Создаем объект MinMaxScaler\n",
    "scaler = MinMaxScaler()\n",
    "\n",
    "# Применяем нормализацию к обучающей выборке\n",
    "X_train_scaled = scaler.fit_transform(X_train)\n",
    "X_train_scaled = pd.DataFrame(X_train_scaled, columns=X_train.columns)\n",
    "\n",
    "# Применяем нормализацию к тестовой выборке\n",
    "X_test_scaled = scaler.transform(X_test)\n",
    "X_test_scaled = pd.DataFrame(X_test_scaled, columns=X_test.columns)\n",
    "\n",
    "# Выводим первые несколько строк нормализованных данных для проверки\n",
    "display(\"Нормализованные данные обучающей выборки:\", X_train_scaled[:5])\n",
    "display(\"Нормализованные данные тестовой выборки:\", X_test_scaled[:5])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6722143a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Рассчитайте среднее арифметическое для первого предиктора (т. е. для первого столбца матрицы) из тестовой выборки. \n",
    "# Ответ округлите до двух знаков после точки-разделителя.\n",
    "\n",
    "mean_first_predictor = X_test_scaled.iloc[:, 0].mean()\n",
    "display(f'Среднее арифметическое для первого предиктора {mean_first_predictor:.2f}')\n",
    "# 0.47 должно быть"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0894c632",
   "metadata": {},
   "source": [
    "# Часть 4: Решение задачи классификации: логистическая регрессия и решающие деревья"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "41b8ff06",
   "metadata": {},
   "source": [
    "### Задание 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8acc0166",
   "metadata": {},
   "outputs": [],
   "source": [
    "# обучите логистическую регрессию и рассчитайте метрики качества\n",
    "log_model = linear_model.LogisticRegression(random_state=42, solver='sag', max_iter=1000)\n",
    "log_model.fit(X_train_scaled, y_train)\n",
    "y_test_pred = log_model.predict(X_test_scaled)\n",
    "y_train_pred = log_model.predict(X_train_scaled)\n",
    "print(f'Мерики на тестовых даннных\\n {metrics.classification_report(y_test, y_test_pred)}')\n",
    "print(f'Мерики на тренировочных данных\\n {metrics.classification_report(y_train, y_train_pred)}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "29b7e0ba",
   "metadata": {},
   "source": [
    "### Задания 2,3,4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c91a588b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# обучите решающие деревья, настройте максимальную глубину\n",
    "\n",
    "tree_model = tree.DecisionTreeClassifier(random_state=42, criterion='entropy')\n",
    "tree_model.fit(X_train_scaled, y_train)\n",
    "y_test_pred = tree_model.predict(X_test_scaled)\n",
    "y_train_pred = tree_model.predict(X_train_scaled)\n",
    "print(f'Мерики на тестовых даннных\\n {metrics.classification_report(y_test, y_test_pred)}')\n",
    "print(f'Мерики на тренировочных данных\\n {metrics.classification_report(y_train, y_train_pred)}')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fbb1010c",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn import tree, metrics\n",
    "import numpy as np\n",
    "\n",
    "# Диапазон значений для максимальной глубины дерева\n",
    "max_depths = range(1, 7)\n",
    "\n",
    "# Списки для хранения точности на обучающей и тестовой выборках\n",
    "train_accuracies = []\n",
    "test_accuracies = []\n",
    "\n",
    "# Перебираем различные значения максимальной глубины\n",
    "for max_depth in max_depths:\n",
    "    # Создаем и обучаем модель дерева решений\n",
    "    tree_model = tree.DecisionTreeClassifier(random_state=42, criterion='entropy', max_depth=max_depth)\n",
    "    tree_model.fit(X_train_scaled, y_train)\n",
    "    \n",
    "    # Предсказания на обучающей и тестовой выборках\n",
    "    y_train_pred = tree_model.predict(X_train_scaled)\n",
    "    y_test_pred = tree_model.predict(X_test_scaled)\n",
    "    \n",
    "    # Вычисляем точность\n",
    "    train_accuracy = metrics.accuracy_score(y_train, y_train_pred)\n",
    "    test_accuracy = metrics.accuracy_score(y_test, y_test_pred)\n",
    "    \n",
    "    # Сохраняем точность\n",
    "    train_accuracies.append(train_accuracy)\n",
    "    test_accuracies.append(test_accuracy)\n",
    "\n",
    "# Находим максимальную глубину, при которой точность на тестовой выборке максимальна, но не наблюдается переобучения\n",
    "optimal_depth = max_depths[np.argmax(test_accuracies)]\n",
    "\n",
    "# Выводим результаты\n",
    "print(f'Оптимальная глубина дерева: {optimal_depth}')\n",
    "print(f'Точность на обучающей выборке: {train_accuracies[optimal_depth-1]:.3f}')\n",
    "print(f'Точность на тестовой выборке: {test_accuracies[optimal_depth-1]:.3f}')\n",
    "\n",
    "\n",
    "tree_model = tree.DecisionTreeClassifier(random_state=42, criterion='entropy', max_depth=optimal_depth)\n",
    "tree_model.fit(X_train_scaled, y_train)\n",
    "y_test_pred = tree_model.predict(X_test_scaled)\n",
    "y_train_pred = tree_model.predict(X_train_scaled)\n",
    "print(f'Мерики на тестовых даннных с оптимальной глубиной\\n {metrics.classification_report(y_test, y_test_pred)}')\n",
    "print(f'Мерики на тренировочных данных с оптимальной глубиной\\n {metrics.classification_report(y_train, y_train_pred)}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a4afe456",
   "metadata": {},
   "outputs": [],
   "source": [
    "oo = pd.DataFrame([tree_model.feature_importances_], columns=X_train_scaled.columns)\n",
    "fig = px.bar(x = list(oo.loc[0].sort_values(ascending=False)[0:10].index),\n",
    "    y=round(oo.loc[0].sort_values(ascending=False)[0:10], 2),\n",
    "    text_auto=True,\n",
    "    title='ТОП-10 признаков'    \n",
    ")\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fe823c18",
   "metadata": {},
   "source": [
    "### Задание 5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "63574943",
   "metadata": {},
   "outputs": [],
   "source": [
    "# подберите оптимальные параметры с помощью gridsearch\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "# задаём сетку параметров\n",
    "param_grid = [\n",
    "              {'min_samples_split': [2, 5, 7, 10] , # Минимальное количество выборок, необходимое для разделения внутреннего узла\n",
    "              'max_depth':[3,5,7] # Максимальная глубина дерева\n",
    "               }              \n",
    "]\n",
    "\n",
    "grid_search = GridSearchCV(\n",
    "    estimator=tree.DecisionTreeClassifier(criterion='entropy',\n",
    "        random_state=42 #генератор случайных чисел\n",
    "        ), \n",
    "    param_grid=param_grid, \n",
    "    n_jobs = -1,\n",
    "    scoring='f1'\n",
    ")  \n",
    "\n",
    "grid_search.fit(X_train_scaled, y_train) \n",
    "print(f'Best Hyperparameter Values: {grid_search.best_params_}')\n",
    "print(f'Best Models:{grid_search.best_estimator_}')\n",
    "print(f'Best score Cross validation: {grid_search.best_score_:.3f}')\n",
    "y_test_pred = grid_search.predict(X_test_scaled)\n",
    "y_train_pred = grid_search.predict(X_train_scaled)\n",
    "print(f'Мерики на тестовых даннных\\n {metrics.classification_report(y_test, y_test_pred)}')\n",
    "print(f'Мерики на тренировочных данных\\n {metrics.classification_report(y_train, y_train_pred)}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ed0fc831",
   "metadata": {},
   "source": [
    "# Часть 5: Решение задачи классификации: ансамбли моделей и построение прогноза"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f9e36ff2",
   "metadata": {},
   "source": [
    "### Задание 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e708e3fe",
   "metadata": {},
   "outputs": [],
   "source": [
    "# обучите на ваших данных случайный лес\n",
    "# from sklearn.ensemble import RandomForestClassifier\n",
    "# from sklearn import metrics\n",
    "\n",
    "# Создаем и обучаем модель случайного леса\n",
    "rf_model = RandomForestClassifier(\n",
    "    n_estimators=100,\n",
    "    criterion='gini',\n",
    "    min_samples_leaf=5,\n",
    "    max_depth=10,\n",
    "    random_state=42\n",
    ")\n",
    "\n",
    "# Обучаем модель на обучающей выборке\n",
    "rf_model.fit(X_train_scaled, y_train)\n",
    "\n",
    "# Предсказания на тестовой и обучающей выборках\n",
    "y_test_pred = rf_model.predict(X_test_scaled)\n",
    "y_train_pred = rf_model.predict(X_train_scaled)\n",
    "\n",
    "# Выводим метрики на тестовых данных\n",
    "print(f'Метрики на тестовых данных\\n{metrics.classification_report(y_test, y_test_pred)}')\n",
    "\n",
    "# Выводим метрики на обучающих данных\n",
    "print(f'Метрики на обучающих данных\\n{metrics.classification_report(y_train, y_train_pred)}')\n",
    "\n",
    "# accuracy 0.83\n",
    "# recall 0.84\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "71d7b13d",
   "metadata": {},
   "source": [
    "### Задания 2 и 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "99f12dfe",
   "metadata": {},
   "outputs": [],
   "source": [
    "# используйте для классификации градиентный бустинг и сравните качество со случайным лесом\n",
    "\n",
    "# Создаем и обучаем модель градиентного бустинга\n",
    "gb_model = GradientBoostingClassifier(\n",
    "    learning_rate=0.05,\n",
    "    n_estimators=300,\n",
    "    min_samples_leaf=5,\n",
    "    max_depth=5,\n",
    "    random_state=42\n",
    ")\n",
    "\n",
    "# Обучаем модель на обучающей выборке\n",
    "gb_model.fit(X_train_scaled, y_train)\n",
    "\n",
    "# Предсказания на тестовой и обучающей выборках\n",
    "y_test_pred = gb_model.predict(X_test_scaled)\n",
    "y_train_pred = gb_model.predict(X_train_scaled)\n",
    "\n",
    "# Выводим метрики на тестовых данных\n",
    "print(f'Метрики на тестовых данных\\n{metrics.classification_report(y_test, y_test_pred)}')\n",
    "\n",
    "# Выводим метрики на обучающих данных\n",
    "print(f'Метрики на обучающих данных\\n{metrics.classification_report(y_train, y_train_pred)}')\n",
    "\n",
    "#F1 - 0.82"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b08718ae",
   "metadata": {},
   "source": [
    "### Задание 4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0bd42fb0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# объедините уже известные вам алгоритмы с помощью стекинга \n",
    "\n",
    "# Определяем базовые модели\n",
    "decision_tree = DecisionTreeClassifier(random_state=42, criterion='entropy', max_depth=10)\n",
    "logistic_regression = LogisticRegression(random_state=42, max_iter=1000)\n",
    "gradient_boosting = GradientBoostingClassifier(\n",
    "    learning_rate=0.05,\n",
    "    n_estimators=300,\n",
    "    min_samples_leaf=5,\n",
    "    max_depth=5,\n",
    "    random_state=42\n",
    ")\n",
    "\n",
    "# Определяем метамодель\n",
    "meta_model = LogisticRegression(random_state=42, max_iter=1000)\n",
    "\n",
    "# Создаем стекинг-классификатор\n",
    "stacking_model = StackingClassifier(\n",
    "    estimators=[\n",
    "        ('decision_tree', decision_tree),\n",
    "        ('logistic_regression', logistic_regression),\n",
    "        ('gradient_boosting', gradient_boosting)\n",
    "    ],\n",
    "    final_estimator=meta_model,\n",
    "    cv=5\n",
    ")\n",
    "\n",
    "# Обучаем стекинг-модель на обучающей выборке\n",
    "stacking_model.fit(X_train_scaled, y_train)\n",
    "\n",
    "# Предсказания на тестовой и обучающей выборках\n",
    "y_test_pred = stacking_model.predict(X_test_scaled)\n",
    "y_train_pred = stacking_model.predict(X_train_scaled)\n",
    "\n",
    "# Выводим метрики на тестовых данных\n",
    "print(f'Метрики на тестовых данных\\n{metrics.classification_report(y_test, y_test_pred)}')\n",
    "\n",
    "# Выводим метрики на обучающих данных\n",
    "print(f'Метрики на обучающих данных\\n{metrics.classification_report(y_train, y_train_pred)}')\n",
    "\n",
    "# precition = 0.82"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6247a5fb",
   "metadata": {},
   "source": [
    "### Задание 5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "35de769c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# оцените, какие признаки демонстрируют наибольшую  важность в модели градиентного бустинга\n",
    "\n",
    "# Получаем важности признаков\n",
    "feature_importances = gb_model.feature_importances_\n",
    "\n",
    "# Создаем DataFrame для удобства отображения\n",
    "importance_df = pd.DataFrame({\n",
    "    'Feature': X_train_scaled.columns,\n",
    "    'Importance': feature_importances\n",
    "})\n",
    "\n",
    "# Сортируем по важности\n",
    "importance_df = importance_df.sort_values(by='Importance', ascending=False)\n",
    "\n",
    "# Выводим топ-10 признаков по важности\n",
    "print(\"Топ-10 признаков по важности в модели градиентного бустинга:\")\n",
    "print(importance_df.head(10))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "96974dda",
   "metadata": {},
   "source": [
    "### Задания 6,7,8"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c48e29e9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# реализуйте оптимизацию гиперпараметров с помощью Optuna\n",
    "%%time\n",
    "# Функция для оптимизации\n",
    "def objective(trial):\n",
    "    # Определяем гиперпараметры для оптимизации\n",
    "    n_estimators = trial.suggest_int('n_estimators', 100, 200, 1)\n",
    "    max_depth = trial.suggest_int('max_depth', 10, 30, 1)\n",
    "    min_samples_leaf = trial.suggest_int('min_samples_leaf', 2, 10, 1)\n",
    "    \n",
    "    # Создаем модель случайного леса с текущими гиперпараметрами\n",
    "    rf_model = RandomForestClassifier(\n",
    "        n_estimators=n_estimators,\n",
    "        max_depth=max_depth,\n",
    "        min_samples_leaf=min_samples_leaf,\n",
    "        random_state=42\n",
    "    )\n",
    "    \n",
    "    # Оцениваем модель с помощью кросс-валидации\n",
    "    score = cross_val_score(rf_model, X_train_scaled, y_train, cv=5, scoring=make_scorer(f1_score)).mean()\n",
    "    \n",
    "    return score\n",
    "\n",
    "# Создаем исследование Optuna\n",
    "study = optuna.create_study(direction='maximize')\n",
    "study.optimize(objective, n_trials=50)\n",
    "\n",
    "# Выводим лучшие гиперпараметры и лучший результат\n",
    "print(f'Лучшие гиперпараметры: {study.best_params}')\n",
    "print(f'Лучший F1-score: {study.best_value:.3f}')\n",
    "\n",
    "# рассчитаем точность для тестовой выборки\n",
    "model = ensemble.RandomForestClassifier(**study.best_params,random_state=42, )\n",
    "model.fit(X_train_scaled, y_train)\n",
    "y_train_pred = model.predict(X_train_scaled)\n",
    "print(\"accuracy на тестовом наборе: {:.2f}\".format(model.score(X_test_scaled, y_test)))\n",
    "y_test_pred = model.predict(X_test_scaled)\n",
    "print('f1_score на тестовом наборе: {:.2f}'.format(metrics.f1_score(y_test, y_test_pred)))\n",
    "\n",
    "# accuracy = 0.83\n",
    "# f1 = 0.84"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "723fabce",
   "metadata": {},
   "source": [
    "Выводы\n",
    "=====\n",
    "\n",
    "1. Предобработка данных:\n",
    "\n",
    "- Данные были успешно подготовлены для моделирования. Категориальные переменные были преобразованы в числовые с использованием dummy-переменных и LabelEncoder.\n",
    "- Применена min-max нормализация к предикторам, что позволило улучшить сходимость моделей и их производительность.\n",
    "\n",
    "2. Анализ признаков:\n",
    "\n",
    "- Проведен анализ важности признаков с использованием модели градиентного бустинга. Наиболее важные признаки были выявлены, что может помочь в дальнейшем улучшении модели и интерпретации результатов.\n",
    "- Матрица корреляций показала, что некоторые признаки имеют высокую корреляцию с целевой переменной, что может быть полезно для дальнейшего анализа.\n",
    "\n",
    "3. Моделирование:\n",
    "\n",
    "- Были обучены и оценены несколько моделей, включая решающие деревья, случайный лес и градиентный бустинг. Каждая модель показала свои сильные и слабые стороны.\n",
    "- Стекинг, объединяющий несколько моделей, продемонстрировал улучшение качества предсказаний, что подтверждает эффективность использования ансамблевых методов.\n",
    "\n",
    "4. Оптимизация гиперпараметров:\n",
    "\n",
    "- Использование GridSearchCV и Optuna для оптимизации гиперпараметров позволило улучшить производительность моделей. Optuna, в частности, показал себя как мощный инструмент для автоматизированного поиска оптимальных параметров.\n",
    "\n",
    "5. Результаты и рекомендации:\n",
    "\n",
    "- Наилучшие результаты были достигнуты с использованием модели градиентного бустинга и стекинга, что указывает на их высокую эффективность для данной задачи.\n",
    "- Рекомендуется продолжить исследование и оптимизацию моделей, возможно, с использованием дополнительных данных или более сложных архитектур, чтобы еще больше улучшить качество предсказаний."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv313",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}